[{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"visStatistics: The right test, visualised","text":"visStatistics automatically selects visualises appropriate statistical hypothesis tests response predictor variable data frame. choice test depends class, distribution, sample size input variables, well user-defined ‘conf.level’. main function visstat() visualises selected test appropriate graphs (box plots, bar charts, regression lines confidence bands, mosaic plots, residual plots, Q-Q plots), annotated main test results, including assumption checks post-hoc analyses. minimal function call looks like: visstat(dataframe, varsample = \"response\", varfactor = \"predictor\") input data.frame must column-based. varsample varfactor must character strings naming columns data.frame. scripted workflow particularly suited browser-based interfaces rely server-side R applications connected secure databases, users direct access, quick data visualisations, e.g., statistical consulting projects. remainder vignette organised follows: Section 2 summarises decision logic used select statistical test. Sections 3–5 provide background implemented tests illustrate decision logic using examples. Function names parentheses headings indicate corresponding statistical hypothesis test function R, Section 6 outlines main limitations package. Section 7 provides overview implemented tests.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"decision-logic","dir":"Articles","previous_headings":"","what":"Decision logic","title":"visStatistics: The right test, visualised","text":"Throughout remainder, data class \"numeric\" \"integer\" referred numerical, data class \"factor\" referred categorical. significance level α\\alpha, used throughout hypothesis testing, defined 1 - conf.level, conf.level user-controllable argument (defaulting 0.95). choice statistical tests performed function visstat() depends whether data numerical categorical, number levels categorical variable, distribution data, well user-defined ‘conf.level’. function prioritizes interpretable visual output tests remain valid following decision logic:","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"numerical-response-and-categorical-predictor","dir":"Articles","previous_headings":"Decision logic","what":"Numerical response and categorical predictor","title":"visStatistics: The right test, visualised","text":"response numerical predictor categorical, statistical hypothesis test central tendencies selected. categorical predictor exactly two levels, Welch’s t-test (t.test()) applied whenever groups contain 30 observations, validity test supported approximate normality sampling distribution mean central limit theorem Lumley et al. (2002). smaller samples, group - wise normality assessed using Shapiro - Wilk test (shapiro.test()) significance level α\\alpha. groups found approximately normally distributed according Shapiro–Wilk test, Welch’s t-test applied; otherwise, Wilcoxon rank- sum test (wilcox.test()) used. predictors two levels, model Fisher’s one-way analysis variables (ANOVA) (aov()) initially fitted. normality residuals evaluated using Shapiro–Wilk test (shapiro.test()) Anderson-Darling test (ad.test()); residuals considered approximately normal least one two tests yields result exceeding significance threshold α\\alpha. condition met, Bartlett’s test (bartlett.test()) assesses homoscedasticity. variances homogeneous (p>αp > \\alpha), Fisher’s one-way ANOVA (aov()) applied Tukey’s Honestly Significant Differences (HSD) (TukeyHSD()) post-hoc comparison. variances differ significantly (p≤αp \\le \\alpha), Welch’s heteroscedastic one- way ANOVA (oneway.test()) used, also followed Tukey’s HSD. residuals normally distributed according tests (p≤αp \\le \\alpha), Kruskal–Wallis test (kruskal.test()) selected, followed pairwise Wilcoxon tests (pairwise.wilcox.test()). graphical overview decision logic used provided figure . Decision tree used select appropriate statistical test categorical predictor numerical response, based number factor levels, normality, homoscedasticity.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"numerical-response-and-numerical-predictor","dir":"Articles","previous_headings":"Decision logic","what":"Numerical response and numerical predictor","title":"visStatistics: The right test, visualised","text":"response predictor numeric, simple linear regression model (lm()) fitted analysed detail, including residual diagnostics, formal tests, plotting fitted values confidence bands. Note one predictor variable allowed, function designed two-dimensional visualisation.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"both-variables-categorical","dir":"Articles","previous_headings":"Decision logic","what":"Both variables categorical","title":"visStatistics: The right test, visualised","text":"variables categorical, direction assumed; order variables function call affect test statistic, influence graphical output. consistency, continue referring variables predictor response. visstat() tests null hypothesis variables independent using either Pearson’s χ2\\chi^2 test (chisq.test()) Fisher’s exact test (fisher.test()), depending expected cell counts. choice test based Cochran’s rule (Cochran 1954), advises χ2\\chi^2approximation reliable expected cell count less 1 20 percent cells expected counts 5.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"numerical-response-and-categorical-predictor-1","dir":"Articles","previous_headings":"","what":"Numerical response and categorical predictor","title":"visStatistics: The right test, visualised","text":"predictor consists class “factor” two levels response class “numeric” “integer” (mode “numerical”), statistical tests applied compare central tendencies across groups. section describes conditions parametric non-parametric tests chosen, based response type, number factor levels, underlying distributional assumptions.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"categorical-predictor-with-two-levels-welchs-t-test-and-wilcoxon-rank-sum","dir":"Articles","previous_headings":"Numerical response and categorical predictor","what":"Categorical predictor with two levels: Welch’s t-test and Wilcoxon rank-sum","title":"visStatistics: The right test, visualised","text":"predictor variable exactly two levels, Welch’s t-test Wilcoxon rank-sum test applied.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"welchs-t-test-t-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with two levels: Welch’s t-test and Wilcoxon rank-sum","what":"Welch’s t-test (t.test())","title":"visStatistics: The right test, visualised","text":"Welch’s t-test (t.test()) assumes observations independent response variable approximately normally distributed within group. contrast Student’s t-test, require assumption equal variances (homoscedasticity) groups. Welch’s t-test remains valid exhibits minimal loss efficiency even assumptions Student’s t-test – namely, normality equal variances response variable across groups – satisfied (Moser Stevens 1992; Delacre, Lakens, Leys 2017). Therefore, Student’s t-test implemented. Welch’s t-test evaluates null hypothesis means two groups equal without assuming equal variances. test statistic given (Welch 1947; Satterthwaite 1946) t=x‾1−x‾2s12n1+s22n2, t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}},  x‾1\\bar{x}_1 x‾2\\bar{x}_2 sample means, s12s_1^2 s22s_2^2 sample variances, n1n_1, n2n_2 sample sizes two groups. statistic follows t-distribution degrees freedom approximated Welch-Satterthwaite equation: ν≈(s12n1+s22n2)2(s12/n1)2n1−1+(s22/n2)2n2−1. \\nu \\approx \\frac{ \\left( \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2} \\right)^2 }{ \\frac{(s_1^2 / n_1)^2}{n_1 - 1} + \\frac{(s_2^2 / n_2)^2}{n_2 - 1} }. resulting p-value computed t-distribution ν\\nu degrees freedom.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"wilcoxon-rank-sum-test-wilcox-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with two levels: Welch’s t-test and Wilcoxon rank-sum","what":"Wilcoxon rank-sum test (wilcox.test())","title":"visStatistics: The right test, visualised","text":"two-sample Wilcoxon rank-sum test (also known Mann-Whitney test) non-parametric alternative require response variable approximately normally distributed within group. tests difference location two independent distributions (Wilcoxon 1945; Mann Whitney 1947). two groups distributions sufficiently similar shape scale, Wilcoxon rank-sum test can interpreted testing whether medians two populations equal (Hollander, Chicken, Wolfe 2014). two-level factor variable varfactor defines two groups, sample sizes n1n_1 n2n_2. n1+n2n_1 + n_2 observations pooled assigned ranks 11 n1+n2n_1 + n_2. Let WWilcoxonW_{\\text{Wilcoxon}} denote sum ranks assigned group corresponding first level varfactor containing n1n_1 observations. test statistic returned visstat() computed W=WWilcoxon−n1(n1+1)2. W = W_{\\text{Wilcoxon}} - \\frac{n_1(n_1 + 1)}{2}. groups contain fewer 50 observations data contain ties, p-value computed exactly. Otherwise, normal approximation continuity correction used.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"graphical-output","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with two levels: Welch’s t-test and Wilcoxon rank-sum","what":"Graphical output","title":"visStatistics: The right test, visualised","text":"graphical output consists box plots overlaid jittered points display individual observations. Welch’s t-test applied, function includes confidence intervals based user-specified conf.level. title structured follows: First line: Test name chosen significance level α\\alpha. Second line: Null hypotheses automatically adapted based user- specified varsample varfactor. Third line: Test statistic, p-value automated comparison α\\alpha function returns list containing results applied test summary statistics used construct plot.","code":""},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"welchs-t-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with two levels: Welch’s t-test and Wilcoxon rank-sum > Examples","what":"Welch’s t-test","title":"visStatistics: The right test, visualised","text":"Motor Trend Car Road Tests dataset (mtcars) contains 32 observations, mpg denotes miles per (US) gallon, represents transmission type (0 = automatic, 1 = manual).  Increasing confidence level conf.level default 0.95 0.99 results wider confidence intervals, higher confidence level requires conservative bounds ensure interval includes true parameter value greater certainty.","code":"mtcars$am <- as.factor(mtcars$am) t_test_statistics <- visstat(mtcars, \"mpg\", \"am\") mtcars$am <- as.factor(mtcars$am) t_test_statistics_99 <- visstat(mtcars, \"mpg\", \"am\", conf.level = 0.99)"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"wilcoxon-rank-sum-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with two levels: Welch’s t-test and Wilcoxon rank-sum > Examples","what":"Wilcoxon rank sum test","title":"visStatistics: The right test, visualised","text":"Wilcoxon rank sum test exemplified differences central tendencies grades “boys” “girls” class:","code":"grades_gender <- data.frame(   sex = as.factor(c(rep(\"girl\", 21), rep(\"boy\", 23))),   grade = c(     19.3, 18.1, 15.2, 18.3, 7.9, 6.2, 19.4,     20.3, 9.3, 11.3, 18.2, 17.5, 10.2, 20.1, 13.3, 17.2, 15.1, 16.2, 17.0,     16.5, 5.1, 15.3, 17.1, 14.8, 15.4, 14.4, 7.5, 15.5, 6.0, 17.4,     7.3, 14.3, 13.5, 8.0, 19.5, 13.4, 17.9, 17.7, 16.4, 15.6, 17.3, 19.9, 4.4, 2.1   ) )  wilcoxon_statistics <- visstat(grades_gender, \"grade\", \"sex\")"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"categorical-predictor-with-more-than-two-levels","dir":"Articles","previous_headings":"Numerical response and categorical predictor","what":"Categorical predictor with more than two levels","title":"visStatistics: The right test, visualised","text":"predictor class “factor” two levels response mode “numerical”, visstat() either performs Fisher’s one- way ANOVA (Fisher 1971) (aov()), Welch’s heteroscedastic one-way ANOVA (Welch 1951) (oneway.test()) , non-parametric alternative, Kruskal –Wallis test (Kruskal Wallis 1952) (kruskal.test()). remainder section, briefly introduce tests , assumption checks, post-hoc procedures, illustrate test example.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"fishers-one-way-anova-aov","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels","what":"Fisher’s one-way ANOVA (aov())","title":"visStatistics: The right test, visualised","text":"Fisher’s one-way ANOVA (aov()) tests null hypothesis means multiple groups equal. assumes independent observations, normally distributed residuals, homogeneous variances across groups. test statistic ratio variance explained differences among group means (-group variance) unexplained variance within groups: F=-group variancewithin-group variance=∑=1kni(x‾−x‾)2k−1∑=1k∑j=1ni(xij−x‾)2N−k, F = \\frac{\\text{-group variance}}{\\text{within-group variance}} = \\frac{\\frac{\\sum_{=1}^{k} n_i (\\bar{x}_i - \\bar{x})^2}{k - 1}} {\\frac{\\sum_{=1}^{k}\\sum_{j=1}^{n_i}(x_{ij}-\\bar{x}_i)^2}{N - k}}, x‾\\bar{x}_i mean group ii, x‾\\bar{x} overall mean, xijx_{ij} observation jj group ii, nin_i sample size group ii, kk number groups, NN total number observations. null hypothesis, statistic follows F-distribution two parameters degrees freedom: numerator (k−1k - 1) denominator (N−kN - k). resulting p-value computed distribution.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"welchs-heteroscedastic-one-way-anova-oneway-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels","what":"Welch’s heteroscedastic one-way ANOVA (oneway.test())","title":"visStatistics: The right test, visualised","text":"assumptions independent observations normally distributed residuals met, homogeneous variances across groups assumed , Welch’s heteroscedastic one-way ANOVA (oneway.test()) (Welch 1951) provides alternative aov(). compares group means using weights based sample sizes variances. degrees freedom adjusted using Satterthwaite-type approximation (Satterthwaite 1946), resulting F-statistic non-integer degrees freedom.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"kruskalwallis-test-kruskal-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels","what":"Kruskal–Wallis test (kruskal.test())","title":"visStatistics: The right test, visualised","text":"assumption normality met, Kruskal–Wallis test provides non-parametric alternative. compares group distributions based ranked values tests null hypothesis groups come population — specifically, distributions location (Kruskal Wallis 1952). group distributions sufficiently similar shape scale, Kruskal–Wallis test can interpreted testing equality medians across groups (Hollander, Chicken, Wolfe 2014). test statistic defined : H=12N(N+1)∑=1kni(R‾−R‾)2, H = \\frac{12}{N(N+1)} \\sum_{=1}^{k} n_i \\left(\\bar{R}_i - \\bar{R} \\right)^2, nin_i sample size group ii, kk number groups, R‾\\bar{R}_i average rank group ii, NN total sample size, R‾=N+12\\bar{R} = \\frac{N+1}{2} average ranks. null hypothesis, HH approximately follows χ2\\chi^2 distribution k−1k - 1 degrees freedom.","code":""},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"testing-the-assumptions-visanovaassumptions","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels","what":"Testing the assumptions (visAnovaAssumptions())","title":"visStatistics: The right test, visualised","text":"test logic aov() oneway.test() follows respective assumptions. visstat() initially models data using aov() analyses residuals. following conditions met: (1) standardised residuals follow normal distribution, (2) residuals exhibit homoscedasticity (equal variances across groups), test statistic aov() returned. normality assumption satisfied, visstat() applies oneway.test(). normality assumption violated, kruskal.test() used instead. assumptions tested using visAnovaAssumptions() function.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"normality-of-residuals-shapiro-test-and-ad-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels > Testing the assumptions (visAnovaAssumptions())","what":"Normality of residuals (shapiro.test() and ad.test())","title":"visStatistics: The right test, visualised","text":"visAnovaAssumptions() function assesses normality standardised residuals ANOVA fit using Shapiro–Wilk test (shapiro.test()) Anderson–Darling test (ad.test()). Normality assumed least one two tests yields p-value greater α\\alpha. function generates two diagnostic plots: scatter plot standardised residuals fitted means linear model level predictor (varfactor), Q–Q plot standardised residuals.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"equal-variances-across-groups-bartlett-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels > Testing the assumptions (visAnovaAssumptions())","what":"Equal variances across groups (bartlett.test())","title":"visStatistics: The right test, visualised","text":"aov() oneway.test() assess whether two samples drawn normal distributions mean. aov() assumes homogeneity variances across groups, oneway.test() require variances equal. Homoscedasticity assessed using Bartlett’s test (bartlett.test()), tests null hypothesis variances across levels grouping variable equal.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"controlling-the-family-wise-error-rate","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels","what":"Controlling the family-wise error rate","title":"visStatistics: The right test, visualised","text":"significant test result, like identify specific groups differ significantly . However, simple pairwise comparisons group means medians following ANOVA Kruskal–Wallis test increase probability incorrectly declaring significant difference , fact, none. error quantified family-wise error rate αPF\\alpha_{PF} (pronounced “alpha per family tests”), refers probability making least one Type error, , falsely rejecting null hypothesis across pairwise comparisons. Given nn levels categorical variable, M=n⋅(n−1)2 M = \\frac{n \\cdot (n - 1)}{2} pairwise comparisons possible, defining family tests (Abdi 2007).","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"šidák-correction","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels > Controlling the family-wise error rate","what":"Šidák correction","title":"visStatistics: The right test, visualised","text":"αPT\\alpha_{PT} (pronounced “alpha per test”) probability making Type error one comparison, 1−αPT1 - \\alpha_{PT} probability making Type error one comparison. MM comparisons independent , probability making Type error across entire family pairwise comparisons (1−αPT)M(1 - \\alpha_{PT})^M. family-wise error rate given complement (Abdi 2007): αPF=1−(1−αPT)M. \\alpha_{PF} = 1 - (1 - \\alpha_{PT})^M. Let us illustrate inflation family-wise error rate increasing group number nn (equal number levels categorical variable)) following examples: αPT=0.05\\alpha_{PT}=0.05 comparing n=3n=3 groups results family-wise error rate αPF≈14%\\alpha_{PF} \\approx 14\\%, whereas comparing n=6n=6 groups (examples ) already leads probability least one time falsely rejecting null hypothesis αPF≈54%\\alpha_{PF} \\approx 54\\%. Solving last equation defining αPF\\alpha_{PF} αPT\\alpha_{PT} yields Šidák equation (Šidák 1967): αPT=1−(1−αPF)1/M. \\alpha_{PT}=1-(1-{\\alpha_{PF}})^{1/M}.  shows , order achieve given family-wise error rate, corresponding per-test significance level must reduced two groups. visstat() sets αPF\\alpha_{PF} user-defined α=1−\\alpha = 1 -conf.level, resulting αSidak=αPT=αSidak=1−𝚌𝚘𝚗𝚏.𝚕𝚎𝚟𝚎𝚕1/M.\\alpha_{Sidak}=\\alpha_{PT} = \\alpha_{Sidak}= 1 - \\texttt{conf.level}^{1 / M}. default settings result αPF=5%\\alpha_{PF} = 5\\%. example, n=3n = 3 groups, leads αPT=1.70%\\alpha_{PT} = 1.70\\%; n=6n = 6 groups αPT=0.34%\\alpha_{PT} = 0.34\\%; n=10n = 10 groups already small αPT=0.11%\\alpha_{PT} = 0.11\\%. examples illustrate Šidák approach becomes increasingly conservative number comparisons grows. Moreover, since method assumes independence among tests, may overly conservative assumption violated.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"post-hoc-test-following-an-anova-tukeyhsd","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels > Controlling the family-wise error rate","what":"Post-hoc test following an ANOVA: TukeyHSD()","title":"visStatistics: The right test, visualised","text":"contrast general-purpose Šidák correction, Tukey’s Honestly Significant Differences procedure (TukeyHSD()) specifically designed pairwise mean comparisons following ANOVA (either aov() oneway.test()). controls family-wise error rate using critical value studentised range distribution, properly accounts correlated nature pairwise comparisons sharing common residual variance (Hochberg Tamhane 1987). Based user-specified confidence level (conf.level), visstat() constructs confidence intervals pairwise differences factor level means. significant difference two means indicated corresponding confidence interval include zero. visstat() returns HSD-adjusted p-values associated confidence intervals pairwise comparisons.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"post-hoc-test-following-the-kruskalwallis-rank-sum-test-pairwise-wilcox-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels > Controlling the family-wise error rate","what":"Post-hoc test following the Kruskal–Wallis rank sum test: pairwise.wilcox.test()","title":"visStatistics: The right test, visualised","text":"post-hoc analysis following Kruskal–Wallis test, visstat() applies pairwise Wilcoxon rank sum test using pairwise.wilcox.test() compare pair factor levels (see section “Wilcoxon rank-sum test (wilcox.test())”). resulting p-values pairwise comparisons adjusted multiple testing using Holm’s method (Holm 1979): p-values first sorted smallest largest tested thresholds become less strict rank increases. stepwise adjustment assume independence among tests typically less conservative Šidák method, still ensuring strong control family-wise error rate.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"graphical-output-1","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels","what":"Graphical output","title":"visStatistics: The right test, visualised","text":"graphical output tests based numerical response categorical predictor two levels consists two panels: first focuses residual analysis, second actual test chosen decision logic. residual panel addresses assumption normality, graphically formal tests. displays scatter plot standardised residuals versus predicted values, well normal Q–Q plot comparing sample quantiles theoretical quantiles. residuals normally distributed, 5%5\\% standardised residuals exceed approximately |2||2| Q–Q plot data points approximately follow red straight line. assume normality residuals, formal tests normality (Shapiro–Wilk Anderson–Darling) result p-values greater user-defined α\\alpha. assume homogeneity variances, Bartlett’s test (shown first line panel title) also result p-value greater α\\alpha. visstat() illustrates, subsequent graph, either kruskal.test(), oneway.test(), aov() result (see also Section “Decision logic”). neither normality residuals homogeneity variances given, kruskal.test() executed. result illustrated using box plots alongside jittered data points, title displaying p-value kruskal.test(). box plot, number observations per level shown. Different green letters pair box plots indicate two groups considered significantly different, based Holm’s-adjusted pairwise Wilcoxon rank sum test p-values smaller α\\alpha. normality residuals can assumed, parametric test chosen: either aov(), homoscedasticity also assumed, oneway.test() otherwise. visstat() displays name test corresponding FF p-value title. graph shows conf.level ⋅100%\\cdot\\,100\\% confidence intervals wider Šidák-corrected (1−αSidak)⋅100%(1 - \\alpha_{Sidak}) \\cdot 100\\% confidence intervals, alongside jittered data points group. Different green letters pair confidence intervals indicate two groups considered significantly different, based results TukeyHSD() procedure. function returns list containing relevant test statistics along post-hoc-adjusted pp-values pairwise comparisons.","code":""},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"one-way-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels > Examples","what":"One-way test","title":"visStatistics: The right test, visualised","text":"npk dataset reports yield peas (pounds per block) agricultural experiment conducted six blocks. experiment, application three different fertilisers – nitrogen (N), phosphate (P), potassium (K) – varied systematically. block received either none, one, two, three fertilisers,  Normality residuals supported graphical diagnostics (scatter plot standardised residuals, Q-Q plot) formal tests (Shapiro–Wilk Anderson- Darling, p>αp > \\alpha). However, homogeneity variances supported given confidence level (p<αp < \\alpha, bartlett.test()), p-value variance-robust oneway.test() reported. Post-hoc analysis TukeyHSD() shows significant yield differences blocks, share group label (e.g., green letters).","code":"oneway_npk <- visstat(npk, \"yield\", \"block\",conf.level=0.90)"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"anova-example","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels > Examples","what":"ANOVA example","title":"visStatistics: The right test, visualised","text":"InsectSprays dataset reports insect counts agricultural experimental units treated six different insecticides. stabilise variance counts, apply square root transformation response variable.  transformation, homogeneity variances can assumed (p>αp> \\alpha calculated bartlett.test()), test statistic p-value aov() displayed.","code":"insect_sprays_tr <- InsectSprays insect_sprays_tr$count_sqrt <- sqrt(InsectSprays$count) test_statistic_anova=visstat(insect_sprays_tr, \"count_sqrt\", \"spray\") # test_statistic_anova"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"kruskalwallis-rank-sum-test","dir":"Articles","previous_headings":"Numerical response and categorical predictor > Categorical predictor with more than two levels > Examples","what":"Kruskal–Wallis rank sum test","title":"visStatistics: The right test, visualised","text":"iris dataset contains petal width measurements (cm) three different iris species.  example, scatter plots standardised residuals Q-Q plot suggest residuals normally distributed. confirmed small p-values Shapiro–Wilk Anderson-Darling tests. p-values significance level α\\alpha, visstat() switches non-parametric kruskal.test(). Post-hoc analysis using pairwise.wilcox.test() shows significant differences petal width three species, indicated distinct group labels (green letters differ).","code":"visstat(iris, \"Petal.Width\", \"Species\")"},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"simple-linear-regression-lm","dir":"Articles","previous_headings":"Numerical response and numerical predictor","what":"Simple linear regression (lm())","title":"visStatistics: The right test, visualised","text":"predictor varfactor response varsample numerical contain one level , visstat() performs simple linear regression. resulting regression plot displays point estimate regression line y=+b⋅x, y = + b \\cdot x, yy response variable, xx predictor variable, aa intercept, bb slope regression line.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"residual-analysis","dir":"Articles","previous_headings":"Numerical response and numerical predictor > Simple linear regression (lm())","what":"Residual analysis","title":"visStatistics: The right test, visualised","text":"visstat() checks normality standardised residuals lm() graphically using Shapiro–Wilk Anderson-Darling tests. p-values null hypothesis normally distributed residuals tests smaller 1−1 -conf.int, title residual plot display message: “Requirement normally distributed residuals met”. Regardless result residual analysis, visstat() proceeds perform regression. title graphical output indicates chosen confidence level (conf.level), estimated regression parameters confidence intervals p-values, adjusted R2R^2. plot displays raw data, fitted regression line, confidence prediction bands corresponding specified conf.level. visstat() returns list containing regression test statistics, p-values normality tests standardised residuals, pointwise estimates confidence prediction bands.","code":""},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"dataset-cars","dir":"Articles","previous_headings":"Numerical response and numerical predictor > Simple linear regression (lm()) > Examples","what":"dataset: cars","title":"visStatistics: The right test, visualised","text":"cars dataset reports speed cars miles per hour (speed) stopping distance feet (dist).  Increasing confidence level conf.level default 0.95 0.99 results wider confidence prediction bands:  p-values greater conf.level Anderson-Darling normality test Shapiro–Wilk test standardised residuals indicate normality assumption residuals underlying linear regression met.","code":"linreg_cars <- visstat(cars, \"dist\", \"speed\") linreg_cars <- visstat(cars, \"dist\", \"speed\", conf.level = 0.99) linreg_trees <- visstat(trees, \"Volume\", \"Girth\", conf.level = 0.9)"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"dataset-trees","dir":"Articles","previous_headings":"Numerical response and numerical predictor > Simple linear regression (lm()) > Examples","what":"dataset: trees","title":"visStatistics: The right test, visualised","text":"trees dataset provides measurements diameter (Girth, inches), Height (feet), Volume (cubic feet) black cherry trees. example, choose Volume response Girth predictor.  graphical analysis standardised residuals p-values greater α\\alpha Anderson-Darling Shapiro–Wilk tests suggest assumption normally distributed residuals met. Furthermore, linear regression model explains 93% total variance response variable Volume.","code":"linreg_cars <- visstat(trees, \"Volume\", \"Girth\", conf.level = 0.9)"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"both-variables-categorical-1","dir":"Articles","previous_headings":"","what":"Both variables categorical","title":"visStatistics: The right test, visualised","text":"variables categorical (.e., class factor), visstat() tests null hypothesis two variables independent. Observed frequencies typically arranged contingency table, rows index levels ii response variable columns index levels jj predictor variable.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"pearsons-residuals-and-mosaic-plots","dir":"Articles","previous_headings":"Both variables categorical","what":"Pearson’s residuals and mosaic plots","title":"visStatistics: The right test, visualised","text":"Mosaic plots provide graphical representation contingency tables, area tile proportional observed cell frequency. aid interpretation, tiles coloured based Pearson residuals chi- squared test independence. residuals measure standardised deviation observed expected counts null hypothesis independence. Let OijO_{ij} EijE_{ij} denote observed expected frequencies row ii column jj R×CR \\times C contingency table. Pearson residual cell defined rij=Oij−EijEij,=1,…,R,j=1,…,C. r_{ij} = \\frac{O_{ij} - E_{ij}}{\\sqrt{E_{ij}}}, \\quad = 1, \\ldots, R,\\quad j = 1, \\ldots, C.  Positive residuals (shaded blue) indicate observed counts greater expected, negative values suggest -representation (shaded red). Colour shading thus highlights combinations categorical levels contribute overall association.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"pearsons-chi2-test-chisq-test","dir":"Articles","previous_headings":"Both variables categorical","what":"Pearson’s χ2\\chi^2-test (chisq.test())","title":"visStatistics: The right test, visualised","text":"test statistic Pearson’s χ2\\chi^2-test (Pearson 1900) sum squared Pearson residuals: χ2=∑=1R∑j=1Crij2=∑=1R∑j=1C(Oij−Eij)2Eij. \\chi^2 = \\sum_{=1}^{R} \\sum_{j=1}^{C} r_{ij}^2 = \\sum_{=1}^{R} \\sum_{j=1}^{C} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}. test statistic compared chi-squared distribution $ (R - 1)(C - 1)$ degrees freedom. resulting p-value corresponds upper tail probability — , probability observing value greater equal test statistic null hypothesis.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"pearsons-chi2-test-with-yates-continuity-correction","dir":"Articles","previous_headings":"Both variables categorical > Pearson’s χ2\\chi^2-test (chisq.test())","what":"Pearson’s χ2\\chi^2 test with Yates’ continuity correction","title":"visStatistics: The right test, visualised","text":"Yates’ correction applied Pearson χ2\\chi^2 statistic 2×22 \\times 2 contingency tables (one degree freedom). case, approximation discrete sampling distribution continuous χ2\\chi^2 distribution tends overestimate significance level test. correct , Yates proposed subtracting 0.5 absolute difference observed expected counts (Yates 1934), resulting smaller test statistic: χYates2=∑=12∑j=12(|Oij−Eij|−0.5)2Eij. \\chi^2_{\\text{Yates}} = \\sum_{=1}^{2} \\sum_{j=1}^{2} \\frac{(|O_{ij} - E_{ij}| - 0.5)^2}{E_{ij}}. reduced test statistic yields larger p-value, thereby lowering risk Type error. Yates’ continuity correction applied default underlying routine chisq.test(). ## Fisher’s exact test (fisher.test()) χ2\\chi^2 approximation considered reliable expected cell count less 1 20 percent cells expected counts 5 (Cochran 1954)). condition met, Fisher’s exact test (Fisher 1971) (fisher.test()) applied instead, non-parametric method rely large-sample approximations. test calculates exact p-value testing independence conditioning observed margins: row totals Ri=∑j=1COijR_i = \\sum_{j=1}^C O_{ij} column totals Cj=∑=1ROijC_j = \\sum_{=1}^R O_{ij}, defining structure contingency table. 2×22 \\times 2 case, observed table can written : C1C2Row sumsR1aba+bR2cdc+dColumn sumsa+cb+dn \\begin{array}{c|cc|c} & C_1 & C_2 & \\text{Row sums} \\\\\\\\ \\hline R_1 & & b & + b \\\\\\\\ R_2 & c & d & c + d \\\\\\\\ \\hline \\text{Column sums} & + c & b + d & n \\end{array} Let O=[abcd] O = \\begin{bmatrix} & b \\\\\\\\ c & d \\end{bmatrix}  denote observed 2×22 \\times 2 contingency table. exact probability observing table null hypothesis independence, given fixed margins, given hypergeometric probability mass function (PMF) ℙ(O∣R1,R2,C1,C2)=(+ba)(c+dc)(na+c), \\mathbb{P}(O \\mid R_1, R_2, C_1, C_2) = \\frac{\\binom{+ b}{} \\binom{c + d}{c}}{\\binom{n}{+ c}}, n=+b+c+dn = + b + c + d total sample size. p-value computed summing probabilities tables margins whose probabilities null less equal observed table. general R×CR \\times C tables, fisher.test() generalises approach using multivariate hypergeometric distribution.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"test-choice-and-graphical-output","dir":"Articles","previous_headings":"Both variables categorical","what":"Test choice and graphical output","title":"visStatistics: The right test, visualised","text":"expected frequencies sufficiently large - specifically, least 80% cells expected counts greater 5 expected count zero - function uses Pearson’s χ2{\\chi}^2-test (chisq.test()). Otherwise, switches Fisher’s exact test (fisher.test()) (Cochran 1954). 2--2 contingency tables, Yates’ continuity correction (Yates 1934) always applied Pearson’s χ2{\\chi}^2-test. tests independence visstat() displays grouped column plot includes respective test’s p-value title, well mosaic plot showing colour-coded Pearson residuals p-value Pearson’s χ2\\chi^2-test.","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"transforming-a-contingency-table-to-a-data-frame","dir":"Articles","previous_headings":"Both variables categorical","what":"Transforming a contingency table to a data frame","title":"visStatistics: The right test, visualised","text":"following examples tests categorical predictor response based HairEyeColor contingency table. Contingency tables must converted required column-based data.frame using helper function counts_to_cases(). function transforms contingency table HairEyeColor data.frame named HairEyeColourDataFrame.","code":"HairEyeColourDataFrame <- counts_to_cases(as.data.frame(HairEyeColor))"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"examples-3","dir":"Articles","previous_headings":"Both variables categorical","what":"Examples","title":"visStatistics: The right test, visualised","text":"examples section, test null hypothesis hair colour (“Hair”) eye colour (“Eye”) independent .","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"pearsons-chi2-test-chisq-test-1","dir":"Articles","previous_headings":"Both variables categorical > Examples","what":"Pearson’s χ2{\\chi}^2-test (chisq.test())","title":"visStatistics: The right test, visualised","text":"graphical output shows null hypothesis Pearson’s χ2\\chi^2 test – namely, hair colour eye colour independent – must rejected default significance level α=0.05\\alpha=0.05 (p=2.33⋅10−25<αp = 2.33 \\cdot 10^{-25} < \\alpha). mosaic plot indicates strongest deviations due - representation individuals black hair brown eyes, blond hair blue eyes. contrast, individuals blond hair brown eyes - represented.","code":"hair_eye_colour_df <- counts_to_cases(as.data.frame(HairEyeColor)) visstat(hair_eye_colour_df, \"Hair\", \"Eye\")"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"pearsons-chi2-test-with-yates-continuity-correction-1","dir":"Articles","previous_headings":"Both variables categorical > Examples > Pearson’s χ2{\\chi}^2-test (chisq.test())","what":"Pearson’s χ2{\\chi}^2-test with Yate’s continuity correction","title":"visStatistics: The right test, visualised","text":"following example, restrict data participants either black brown hair either brown blue eyes, resulting 2--2 contingency table.  Also reduced dataset reject null hypothesis independence hair colors “brown” “black” eye colours “brown” ” blue”. mosaic plot shows blue eyed persons black hair - represented. Note higher p-value Pearson’s χ2{\\chi}^2-test Yate’s continuity correction (p = 0.00354) compared p-value Pearson’s χ2{\\chi}^2-test (p = 0.00229) shown mosaic plot.","code":"hair_black_brown_eyes_brown_blue <- HairEyeColor[1:2, 1:2, ] # Transform to data frame hair_black_brown_eyes_brown_blue_df <- counts_to_cases(as.data.frame(hair_black_brown_eyes_brown_blue)) # Chi-squared test visstat(hair_black_brown_eyes_brown_blue_df, \"Hair\", \"Eye\")"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"fishers-exact-test-fisher-test","dir":"Articles","previous_headings":"Both variables categorical > Examples","what":"Fisher’s exact test (fisher.test())","title":"visStatistics: The right test, visualised","text":", extract 2--2 contingency table full dataset, time keeping male participants black brown hair hazel green eyes. Pearson’s χ2{\\chi}^2 test applied table yield expected frequency less 5 one four cells (25% cells), violates requirement least 80% expected frequencies must 5 greater (Cochran 1954). Therefore, visstat() automatically selects Fisher’s exact test instead.","code":"hair_eye_colour_male <- HairEyeColor[, , 1] # Slice out a 2 by 2 contingency table black_brown_hazel_green_male <- hair_eye_colour_male[1:2, 3:4] # Transform to data frame black_brown_hazel_green_male <- counts_to_cases(as.data.frame(black_brown_hazel_green_male)) # Fisher test fisher_stats <- visstat(black_brown_hazel_green_male, \"Hair\", \"Eye\")"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"saving-the-graphical-output","dir":"Articles","previous_headings":"Both variables categorical","what":"Saving the graphical output","title":"visStatistics: The right test, visualised","text":"generated graphics can saved file format supported Cairo(), including “png”, “jpeg”, “pdf”, “svg”, “ps”, “tiff” user specified plotDirectory. following example, store graphics png format plotDirectory tempdir(). file names reflect statistical test used variable names involved. Remove graphical output plotDirectory:","code":"#Graphical output written to plotDirectory: In this example  # a bar chart to visualise the Chi-squared test and mosaic plot showing # Pearson's residuals. #chi_squared_or_fisher_Hair_Eye.png and mosaic_complete_Hair_Eye.png visstat(black_brown_hazel_green_male, \"Hair\", \"Eye\",   graphicsoutput = \"png\", plotDirectory = tempdir()) file.remove(file.path(tempdir(), \"chi_squared_or_fisher_Hair_Eye.png\")) file.remove(file.path(tempdir(), \"mosaic_complete_Hair_Eye.png\"))"},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"limitations","dir":"Articles","previous_headings":"","what":"Limitations","title":"visStatistics: The right test, visualised","text":"main purpose package decision-logic based automatic visualisation statistical test results. Therefore, except user-adjustable conf.level parameter, statistical tests applied using default settings corresponding base R functions. consequence, paired tests currently supported visstat() allow study interactions terms different levels independent variable analysis variance. Focusing graphical representation tests, simple linear regression implemented, multiple linear regressions visualised. # Implemented tests","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"numerical-response-and-categorical-predictor-2","dir":"Articles","previous_headings":"Limitations","what":"Numerical response and categorical predictor","title":"visStatistics: The right test, visualised","text":"response numerical predictor categorical, test central tendencies selected: t.test(), wilcox.test(), aov(), oneway.test(),kruskal.test()","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"normality-assumption-check","dir":"Articles","previous_headings":"Limitations > Numerical response and categorical predictor","what":"Normality assumption check","title":"visStatistics: The right test, visualised","text":"shapiro.test() ad.test()","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"homoscedasticity-assumption-check","dir":"Articles","previous_headings":"Limitations > Numerical response and categorical predictor","what":"Homoscedasticity assumption check","title":"visStatistics: The right test, visualised","text":"bartlett.test()","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"post-hoc-tests","dir":"Articles","previous_headings":"Limitations > Numerical response and categorical predictor","what":"Post-hoc tests","title":"visStatistics: The right test, visualised","text":"TukeyHSD() (aov()oneway.test()) pairwise.wilcox.test() (kruskal.test())","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"numerical-response-and-numerical-predictor-2","dir":"Articles","previous_headings":"Limitations","what":"Numerical response and numerical predictor","title":"visStatistics: The right test, visualised","text":"response predictor numerical, simple linear regression model fitted: lm()","code":""},{"path":"https://shhschilling.github.io/visStatistics/articles/visStatistics.html","id":"both-variables-cagegorical","dir":"Articles","previous_headings":"Limitations","what":"Both variables cagegorical","title":"visStatistics: The right test, visualised","text":"variables categorical, visstat() tests null hypothesis independence using one following: chisq.test() (default larger samples) fisher.test() (used small expected cell counts based Cochran’s rule)","code":""},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Sabine Schilling. Maintainer, author, copyright holder.            2025 Peter Kauf. Contributor.","code":""},{"path":"https://shhschilling.github.io/visStatistics/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Schilling S (2025). visStatistics: Automated Selection Visualisation Statistical Hypothesis Tests. R package version 0.1.6, https://github.com/shhschilling/visStatistics.","code":"@Manual{,   title = {visStatistics: Automated Selection and Visualisation of Statistical Hypothesis Tests},   author = {Sabine Schilling},   year = {2025},   note = {R package version 0.1.6},   url = {https://github.com/shhschilling/visStatistics}, }"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"visstatistics-the-right-test-visualised","dir":"","previous_headings":"","what":"Automated Selection and Visualisation of Statistical Hypothesis Tests","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"R package visStatistics allows rapid visualisation statistical analysis raw data. automatically selects visualises appropriate statistical hypothesis test response (varsample) feature (varfactor) within data.frame. package focuses visualising selected test using appropriate plots - box plots, bar charts, regression lines confidence bands, mosaic plots, residual plots Q–Q plots. plot annotated relevant test statistics , applicable, assumption checks post-hoc results. scripted workflow particularly well suited interactive interfaces, users access data graphical front end backed server-side R sessions, well quick data exploration, example, statistical consulting contexts.","code":""},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"minimal function call looks main function visstat() looks like: input must column - based data.frame, varsample varfactor character strings naming columns data frame. function selects statistical test based class response feature variables, number levels categorical variables, conditions normality homoscedasticity. automatically generated output figures illustrate selected statistical test, display main test statistics, include assumption checks post hoc comparisons applicable. primary test results returned list object.","code":"visstat(dataframe, varsample = \"response\", varfactor = \"feature\")"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"installation-of-latest-stable-version-from-cran","dir":"","previous_headings":"","what":"Installation of latest stable version from CRAN","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"1. Install package 2. Load package","code":"install.packages(\"visStatistics\") library(visStatistics)"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"installation-of-the-development-version-from-github","dir":"","previous_headings":"","what":"Installation of the development version from GitHub","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"1. Install devtools CRAN already installed: 2. Load devtools package: 3. Install visStatistics package GitHub: 4. Load visStatistics package: 5. View help main function: 6. Study details package vignette:","code":"install.packages(\"devtools\") library(devtools) install_github(\"shhschilling/visStatistics\") library(visStatistics) ? visstat vignette(\"visStatistics\")"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"decision-logic","dir":"","previous_headings":"","what":"Decision logic","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"Throughout remainder, data class \"numeric\" \"integer\" referred numerical, data class \"factor\" referred categorical. choice statistical tests performed function visstat() depends whether data numerical categorical, number levels categorical variable, distribution data. function prioritizes interpretable visual output tests remain valid following decision logic: response numerical predictor categorical, statistical hypothesis test central tendencies selected. categorical predictor exactly two levels, Welch’s t-test (t.test()) applied whenever groups contain 30 observations, validity test supported approximate normality sampling distribution mean central limit theorem Lumley et al. (2002). smaller samples, group - wise normality assessed using Shapiro - Wilk test (shapiro.test()) significance level α. groups found approximately normally distributed according Shapiro - Wilk test, Welch’s t-test applied; otherwise, Wilcoxon rank-sum test (wilcox.test()) used. predictors two levels, model Fisher’s one-way analysis variables (ANOVA) (aov()) initially fitted. normality residuals evaluated using Shapiro-Wilk test (shapiro.test()) Anderson-Darling test (ad.test()); residuals considered approximately normal least one two tests yields result exceeding significance threshold α. condition met, Bartlett’s test (bartlett.test()) used assess homoscedasticity. variances homogeneous (p > α), Fisher’s one-way ANOVA (aov()) applied Tukey’s Honestly Significant Differences (HSD) (TukeyHSD()) post-hoc comparison. variances differ significantly (p ≤ α), Welch’s heteroscedastic one-way ANOVA (oneway.test()) used, also followed Tukey’s HSD. residuals normally distributed according tests (p ≤ α), Kruskal-Wallis test (kruskal.test()) selected, followed pairwise Wilcoxon tests (pairwise.wilcox.test()). graphical overview decision logic used provided figure .  Decision tree used select appropriate statistical test categorical predictor numerical response, based number factor levels, normality, homoscedasticity. response predictor numerical, simple linear regression model (lm()) fitted analysed detail, including residual diagnostics, formal tests, plotting fitted values confidence bands. Note one explanatory variable allowed, function designed two-dimensional visualisation. r case two categorical variables, visstat() tests null hypothesis predictor response variables independent using either Pearson’s χ2-test (chisq.test()) Fisher’s exact test (fisher.test()). choice test based Cochran’s rule (Cochran 1954), advises χ2approximation reliable expected cell count less 1 20 percent cells expected counts 5. Note: Except user - adjustable conf.level parameter, statistical tests applied using default settings corresponding base R functions (e.g., t.test()). consequence, paired tests currently supported. Furthermore, since main purpose package visualize statistical test results, simple linear regression implemented. detailed description underlying decision logic see","code":"vignette(\"visStatistics\")"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"section, function names parentheses headings indicate statistical test selected decision logic visstat().","code":"library(visStatistics)"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"numerical-response-and-categorical-feature","dir":"","previous_headings":"","what":"Numerical response and categorical feature","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"response numerical feature categorical, test central tendencies selected.","code":""},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"insectsprays-dataset","dir":"","previous_headings":"Numerical response and categorical feature > Welch’s t-test (t.test())","what":"InsectSprays dataset","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"","code":"insect_sprays_a_b <- InsectSprays[which(InsectSprays$spray == \"A\" | InsectSprays$spray == \"B\"), ] insect_sprays_a_b$spray <- factor(insect_sprays_a_b$spray) visstat(insect_sprays_a_b, \"count\", \"spray\")"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"mtcars-dataset","dir":"","previous_headings":"Numerical response and categorical feature > Welch’s t-test (t.test())","what":"mtcars dataset","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"","code":"mtcars$am <- as.factor(mtcars$am) t_test_statistics <- visstat(mtcars, \"mpg\", \"am\") #t_test_statistics"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"wilcoxon-rank-sum-test-wilcoxtest","dir":"","previous_headings":"Numerical response and categorical feature","what":"Wilcoxon rank-sum test (wilcox.test())","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"","code":"grades_gender <- data.frame(   sex = factor(rep(c(\"girl\", \"boy\"), times = c(21, 23))),   grade = c(     19.3, 18.1, 15.2, 18.3, 7.9, 6.2, 19.4, 20.3, 9.3, 11.3,     18.2, 17.5, 10.2, 20.1, 13.3, 17.2, 15.1, 16.2, 17.0, 16.5, 5.1,     15.3, 17.1, 14.8, 15.4, 14.4, 7.5, 15.5, 6.0, 17.4, 7.3, 14.3,     13.5, 8.0, 19.5, 13.4, 17.9, 17.7, 16.4, 15.6, 17.3, 19.9, 4.4, 2.1   ) )  wilcoxon_statistics <- visstat(grades_gender, \"grade\", \"sex\")"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"fishers-one-way-anova-aov","dir":"","previous_headings":"Numerical response and categorical feature","what":"Fisher’s one-way ANOVA (aov())","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"","code":"insect_sprays_tr <- InsectSprays insect_sprays_tr$count_sqrt <- sqrt(InsectSprays$count) visstat(insect_sprays_tr, \"count_sqrt\", \"spray\")"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"welchs-heteroscedastic-one-way-anova-onewaytest","dir":"","previous_headings":"Numerical response and categorical feature","what":"Welch’s heteroscedastic one-way ANOVA (oneway.test())","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"","code":"one_way_npk <- visstat(npk, \"yield\", \"block\")"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"kruskalwallis-test-kruskaltest","dir":"","previous_headings":"Numerical response and categorical feature","what":"Kruskal–Wallis test (kruskal.test())","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"generated graphs can saved available formats Cairo package. save graphical output type “pdf” plotDirectory tempdir():","code":"visstat(iris, \"Petal.Width\", \"Species\") visstat( iris, \"Petal.Width\", \"Species\", graphicsoutput = \"pdf\", plotDirectory = tempdir() )"},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"simple-linear-regression-lm","dir":"","previous_headings":"Numerical response and numerical feature:","what":"Simple linear Regression (lm())","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"Increasing confidence level conf.level default 0.95 0.99 leads two wider confidence prediction bands:","code":"linreg_cars <- visstat(cars, \"dist\", \"speed\")"},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"pearsons-χ2-test-chisqtest","dir":"","previous_headings":"Categorical response and categorical feature","what":"Pearson’s χ2-test (chisq.test())","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"Count datasets often presented multidimensional arrays, - called contingency tables, whereas visstat() requires data.frame column structure. Arrays can transformed column wise structure helper function counts_to_cases():","code":"hair_eye_color_df <- counts_to_cases(as.data.frame(HairEyeColor)) visstat(hair_eye_color_df, \"Hair\", \"Eye\")"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"fishers-exact-test-fishertest","dir":"","previous_headings":"Categorical response and categorical feature","what":"Fisher’s exact test (fisher.test())","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"","code":"hair_eye_color_male <- HairEyeColor[, , 1] # Slice out a 2 by 2 contingency table black_brown_hazel_green_male <- hair_eye_color_male[1:2, 3:4] # Transform to data frame black_brown_hazel_green_male <- counts_to_cases(as.data.frame(black_brown_hazel_green_male)) # Fisher test fisher_stats <- visstat(black_brown_hazel_green_male, \"Hair\", \"Eye\")"},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"implemented-tests","dir":"","previous_headings":"","what":"Implemented tests","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"Note test implemented default settings, exception user-adjustable conf.level.","code":""},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"main-tests","dir":"","previous_headings":"Implemented tests > Numerical response and categorical feature","what":"Main tests","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"t.test(), wilcox.test(), aov(), oneway.test(), kruskal.test()","code":""},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"normality-assumption-check","dir":"","previous_headings":"Implemented tests > Numerical response and categorical feature","what":"Normality assumption check","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"shapiro.test() ad.test()","code":""},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"homoscedasticity-assumption-check","dir":"","previous_headings":"Implemented tests > Numerical response and categorical feature","what":"Homoscedasticity assumption check","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"bartlett.test()","code":""},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"post-hoc-tests","dir":"","previous_headings":"Implemented tests > Numerical response and categorical feature","what":"Post-hoc tests","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"TukeyHSD() (used following aov()oneway.test()) pairwise.wilcox.test() (used following kruskal.test())","code":""},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"numerical-response-and-numerical-feature-1","dir":"","previous_headings":"Implemented tests","what":"Numerical response and numerical feature:","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"Simple linear regression: lm() Note multiple linear regression models implemented, package focuses visualisation data, model building.","code":""},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"categorical-response-and-categorical-feature-1","dir":"","previous_headings":"Implemented tests","what":"Categorical response and categorical feature","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"chisq.test() (default larger samples) fisher.test() (used small expected cell counts based Cochran’s rule (Cochran 1954))","code":""},{"path":"https://shhschilling.github.io/visStatistics/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Automated Selection and Visualisation of Statistical Hypothesis Tests","text":"Cochran, William G. 1954. “Combination Estimates Different Experiments.” Biometrics 10 (1): 101. https://doi.org/10.2307/3001666. Lumley, Thomas, Paula Diehr, Scott Emerson, Lu Chen. 2002. “Importance Normality Assumption Large Public Health Data Sets.” Annual Review Public Health 23: 151–69. https://doi.org/10.1146/annurev.publhealth.23.100901.140546. Rasch, Dieter, Klaus D. Kubinger, Karl Moder. 2011. “Two-Sample t Test: Pre-Testing Assumptions Pay .” Statistical Papers 52 (1): 219–31. https://doi.org/10.1007/s00362-009-0224-x.","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/colorscheme.html","id":null,"dir":"Reference","previous_headings":"","what":"colorscheme(x) selects color scheme of graphical output. Function parameter NULL lists all available color schemes, 1 a color tuple of green and blue 2 a color tuple of dark green and turquoi, 3 a colorplaette as defined by RcolorBrewer — colorscheme","title":"colorscheme(x) selects color scheme of graphical output. Function parameter NULL lists all available color schemes, 1 a color tuple of green and blue 2 a color tuple of dark green and turquoi, 3 a colorplaette as defined by RcolorBrewer — colorscheme","text":"colorscheme(x) selects color scheme graphical output. Function parameter NULL lists available color schemes, 1 color tuple green blue 2 color tuple dark green turquoi, 3 colorplaette defined RcolorBrewer","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/colorscheme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"colorscheme(x) selects color scheme of graphical output. Function parameter NULL lists all available color schemes, 1 a color tuple of green and blue 2 a color tuple of dark green and turquoi, 3 a colorplaette as defined by RcolorBrewer — colorscheme","text":"","code":"colorscheme(colorcode = NULL)"},{"path":"https://shhschilling.github.io/visStatistics/reference/colorscheme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"colorscheme(x) selects color scheme of graphical output. Function parameter NULL lists all available color schemes, 1 a color tuple of green and blue 2 a color tuple of dark green and turquoi, 3 a colorplaette as defined by RcolorBrewer — colorscheme","text":"colorcode selects color scheme. parameters NULL: list available color schemes, 1: colortuple, 2, colortuple2, 3, ColorPalette","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/colorscheme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"colorscheme(x) selects color scheme of graphical output. Function parameter NULL lists all available color schemes, 1 a color tuple of green and blue 2 a color tuple of dark green and turquoi, 3 a colorplaette as defined by RcolorBrewer — colorscheme","text":"selected color scheme, colors given Hex Code #RRGGBB names","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/counts_to_cases.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data frame of counts to data frame of cases. data frame must contain a column with frequencies (counts) as generated by as.data.frame from a contingency table — counts_to_cases","title":"Convert data frame of counts to data frame of cases. data frame must contain a column with frequencies (counts) as generated by as.data.frame from a contingency table — counts_to_cases","text":"Convert data frame counts data frame cases. data frame must contain column frequencies (counts) generated .data.frame contingency table","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/counts_to_cases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data frame of counts to data frame of cases. data frame must contain a column with frequencies (counts) as generated by as.data.frame from a contingency table — counts_to_cases","text":"","code":"counts_to_cases(x, countcol = \"Freq\")"},{"path":"https://shhschilling.github.io/visStatistics/reference/counts_to_cases.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data frame of counts to data frame of cases. data frame must contain a column with frequencies (counts) as generated by as.data.frame from a contingency table — counts_to_cases","text":"x data.frame counts generated contingency table. countcol character string, name column x containing counts. Default name column  'Freq'.","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/counts_to_cases.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data frame of counts to data frame of cases. data frame must contain a column with frequencies (counts) as generated by as.data.frame from a contingency table — counts_to_cases","text":"data frame cases dimension (total number counts sum 'Freq' x) times 2.","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/counts_to_cases.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data frame of counts to data frame of cases. data frame must contain a column with frequencies (counts) as generated by as.data.frame from a contingency table — counts_to_cases","text":"","code":"counts_to_cases(as.data.frame(HairEyeColor[, , 1]), countcol = \"Freq\") #>        Hair   Eye #> 1     Black Brown #> 1.1   Black Brown #> 1.2   Black Brown #> 1.3   Black Brown #> 1.4   Black Brown #> 1.5   Black Brown #> 1.6   Black Brown #> 1.7   Black Brown #> 1.8   Black Brown #> 1.9   Black Brown #> 1.10  Black Brown #> 1.11  Black Brown #> 1.12  Black Brown #> 1.13  Black Brown #> 1.14  Black Brown #> 1.15  Black Brown #> 1.16  Black Brown #> 1.17  Black Brown #> 1.18  Black Brown #> 1.19  Black Brown #> 1.20  Black Brown #> 1.21  Black Brown #> 1.22  Black Brown #> 1.23  Black Brown #> 1.24  Black Brown #> 1.25  Black Brown #> 1.26  Black Brown #> 1.27  Black Brown #> 1.28  Black Brown #> 1.29  Black Brown #> 1.30  Black Brown #> 1.31  Black Brown #> 2     Brown Brown #> 2.1   Brown Brown #> 2.2   Brown Brown #> 2.3   Brown Brown #> 2.4   Brown Brown #> 2.5   Brown Brown #> 2.6   Brown Brown #> 2.7   Brown Brown #> 2.8   Brown Brown #> 2.9   Brown Brown #> 2.10  Brown Brown #> 2.11  Brown Brown #> 2.12  Brown Brown #> 2.13  Brown Brown #> 2.14  Brown Brown #> 2.15  Brown Brown #> 2.16  Brown Brown #> 2.17  Brown Brown #> 2.18  Brown Brown #> 2.19  Brown Brown #> 2.20  Brown Brown #> 2.21  Brown Brown #> 2.22  Brown Brown #> 2.23  Brown Brown #> 2.24  Brown Brown #> 2.25  Brown Brown #> 2.26  Brown Brown #> 2.27  Brown Brown #> 2.28  Brown Brown #> 2.29  Brown Brown #> 2.30  Brown Brown #> 2.31  Brown Brown #> 2.32  Brown Brown #> 2.33  Brown Brown #> 2.34  Brown Brown #> 2.35  Brown Brown #> 2.36  Brown Brown #> 2.37  Brown Brown #> 2.38  Brown Brown #> 2.39  Brown Brown #> 2.40  Brown Brown #> 2.41  Brown Brown #> 2.42  Brown Brown #> 2.43  Brown Brown #> 2.44  Brown Brown #> 2.45  Brown Brown #> 2.46  Brown Brown #> 2.47  Brown Brown #> 2.48  Brown Brown #> 2.49  Brown Brown #> 2.50  Brown Brown #> 2.51  Brown Brown #> 2.52  Brown Brown #> 3       Red Brown #> 3.1     Red Brown #> 3.2     Red Brown #> 3.3     Red Brown #> 3.4     Red Brown #> 3.5     Red Brown #> 3.6     Red Brown #> 3.7     Red Brown #> 3.8     Red Brown #> 3.9     Red Brown #> 4     Blond Brown #> 4.1   Blond Brown #> 4.2   Blond Brown #> 5     Black  Blue #> 5.1   Black  Blue #> 5.2   Black  Blue #> 5.3   Black  Blue #> 5.4   Black  Blue #> 5.5   Black  Blue #> 5.6   Black  Blue #> 5.7   Black  Blue #> 5.8   Black  Blue #> 5.9   Black  Blue #> 5.10  Black  Blue #> 6     Brown  Blue #> 6.1   Brown  Blue #> 6.2   Brown  Blue #> 6.3   Brown  Blue #> 6.4   Brown  Blue #> 6.5   Brown  Blue #> 6.6   Brown  Blue #> 6.7   Brown  Blue #> 6.8   Brown  Blue #> 6.9   Brown  Blue #> 6.10  Brown  Blue #> 6.11  Brown  Blue #> 6.12  Brown  Blue #> 6.13  Brown  Blue #> 6.14  Brown  Blue #> 6.15  Brown  Blue #> 6.16  Brown  Blue #> 6.17  Brown  Blue #> 6.18  Brown  Blue #> 6.19  Brown  Blue #> 6.20  Brown  Blue #> 6.21  Brown  Blue #> 6.22  Brown  Blue #> 6.23  Brown  Blue #> 6.24  Brown  Blue #> 6.25  Brown  Blue #> 6.26  Brown  Blue #> 6.27  Brown  Blue #> 6.28  Brown  Blue #> 6.29  Brown  Blue #> 6.30  Brown  Blue #> 6.31  Brown  Blue #> 6.32  Brown  Blue #> 6.33  Brown  Blue #> 6.34  Brown  Blue #> 6.35  Brown  Blue #> 6.36  Brown  Blue #> 6.37  Brown  Blue #> 6.38  Brown  Blue #> 6.39  Brown  Blue #> 6.40  Brown  Blue #> 6.41  Brown  Blue #> 6.42  Brown  Blue #> 6.43  Brown  Blue #> 6.44  Brown  Blue #> 6.45  Brown  Blue #> 6.46  Brown  Blue #> 6.47  Brown  Blue #> 6.48  Brown  Blue #> 6.49  Brown  Blue #> 7       Red  Blue #> 7.1     Red  Blue #> 7.2     Red  Blue #> 7.3     Red  Blue #> 7.4     Red  Blue #> 7.5     Red  Blue #> 7.6     Red  Blue #> 7.7     Red  Blue #> 7.8     Red  Blue #> 7.9     Red  Blue #> 8     Blond  Blue #> 8.1   Blond  Blue #> 8.2   Blond  Blue #> 8.3   Blond  Blue #> 8.4   Blond  Blue #> 8.5   Blond  Blue #> 8.6   Blond  Blue #> 8.7   Blond  Blue #> 8.8   Blond  Blue #> 8.9   Blond  Blue #> 8.10  Blond  Blue #> 8.11  Blond  Blue #> 8.12  Blond  Blue #> 8.13  Blond  Blue #> 8.14  Blond  Blue #> 8.15  Blond  Blue #> 8.16  Blond  Blue #> 8.17  Blond  Blue #> 8.18  Blond  Blue #> 8.19  Blond  Blue #> 8.20  Blond  Blue #> 8.21  Blond  Blue #> 8.22  Blond  Blue #> 8.23  Blond  Blue #> 8.24  Blond  Blue #> 8.25  Blond  Blue #> 8.26  Blond  Blue #> 8.27  Blond  Blue #> 8.28  Blond  Blue #> 8.29  Blond  Blue #> 9     Black Hazel #> 9.1   Black Hazel #> 9.2   Black Hazel #> 9.3   Black Hazel #> 9.4   Black Hazel #> 9.5   Black Hazel #> 9.6   Black Hazel #> 9.7   Black Hazel #> 9.8   Black Hazel #> 9.9   Black Hazel #> 10    Brown Hazel #> 10.1  Brown Hazel #> 10.2  Brown Hazel #> 10.3  Brown Hazel #> 10.4  Brown Hazel #> 10.5  Brown Hazel #> 10.6  Brown Hazel #> 10.7  Brown Hazel #> 10.8  Brown Hazel #> 10.9  Brown Hazel #> 10.10 Brown Hazel #> 10.11 Brown Hazel #> 10.12 Brown Hazel #> 10.13 Brown Hazel #> 10.14 Brown Hazel #> 10.15 Brown Hazel #> 10.16 Brown Hazel #> 10.17 Brown Hazel #> 10.18 Brown Hazel #> 10.19 Brown Hazel #> 10.20 Brown Hazel #> 10.21 Brown Hazel #> 10.22 Brown Hazel #> 10.23 Brown Hazel #> 10.24 Brown Hazel #> 11      Red Hazel #> 11.1    Red Hazel #> 11.2    Red Hazel #> 11.3    Red Hazel #> 11.4    Red Hazel #> 11.5    Red Hazel #> 11.6    Red Hazel #> 12    Blond Hazel #> 12.1  Blond Hazel #> 12.2  Blond Hazel #> 12.3  Blond Hazel #> 12.4  Blond Hazel #> 13    Black Green #> 13.1  Black Green #> 13.2  Black Green #> 14    Brown Green #> 14.1  Brown Green #> 14.2  Brown Green #> 14.3  Brown Green #> 14.4  Brown Green #> 14.5  Brown Green #> 14.6  Brown Green #> 14.7  Brown Green #> 14.8  Brown Green #> 14.9  Brown Green #> 14.10 Brown Green #> 14.11 Brown Green #> 14.12 Brown Green #> 14.13 Brown Green #> 14.14 Brown Green #> 15      Red Green #> 15.1    Red Green #> 15.2    Red Green #> 15.3    Red Green #> 15.4    Red Green #> 15.5    Red Green #> 15.6    Red Green #> 16    Blond Green #> 16.1  Blond Green #> 16.2  Blond Green #> 16.3  Blond Green #> 16.4  Blond Green #> 16.5  Blond Green #> 16.6  Blond Green #> 16.7  Blond Green"},{"path":"https://shhschilling.github.io/visStatistics/reference/openGraphCairo.html","id":null,"dir":"Reference","previous_headings":"","what":"Cairo wrapper function — openGraphCairo","title":"Cairo wrapper function — openGraphCairo","text":"Cairo wrapper function returning NULL type specified","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/openGraphCairo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cairo wrapper function — openGraphCairo","text":"","code":"openGraphCairo(   width = 640,   height = 480,   fileName = NULL,   type = NULL,   fileDirectory = getwd(),   pointsize = 12,   bg = \"transparent\",   canvas = \"white\",   units = \"px\",   dpi = 150 )"},{"path":"https://shhschilling.github.io/visStatistics/reference/openGraphCairo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cairo wrapper function — openGraphCairo","text":"width see Cairo() height see Cairo() fileName name file created. include file extension '.type' file filedirectory. Default file name 'visstat_plot'. type Supported output types 'png', 'jpeg', 'pdf', 'svg', 'ps' 'tiff'. See Cairo() fileDirectory path directory, plot stored. Default current working directory. pointsize see Cairo() bg see Cairo() canvas see Cairo() units see Cairo() dpi DPI used conversion units pixels. Default value 150.","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/openGraphCairo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cairo wrapper function — openGraphCairo","text":"NULL, type specified. Otherwise see Cairo()","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/openGraphCairo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cairo wrapper function — openGraphCairo","text":"openGraphCairo() Cairo() wrapper function. Differences Cairo: ) prematurely ends function call Cairo() returning NULL, output type  types 'png', 'jpeg', 'pdf', 'svg', 'ps' 'tiff' provided. b) file argument underlying Cairo function generated file.path(fileDirectory,paste(fileName,'.', type, sep = '')).","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/openGraphCairo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cairo wrapper function — openGraphCairo","text":"","code":"##  adapted from example in \\code{Cairo()} openGraphCairo(fileName = \"normal_dist\", type = \"pdf\", fileDirectory = tempdir()) plot(rnorm(4000), rnorm(4000), col = \"#ff000018\", pch = 19, cex = 2) dev.off() # creates a file 'normal_dist.pdf' in the directory specified in fileDirectory #> pdf  #>   2  # ## remove the plot from fileDirectory file.remove(file.path(tempdir(), \"normal_dist.pdf\")) #> [1] TRUE"},{"path":"https://shhschilling.github.io/visStatistics/reference/saveGraphVisstat.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves Graphical Output — saveGraphVisstat","title":"Saves Graphical Output — saveGraphVisstat","text":"Closes graphical devices dev.() saves output fileName type provided.","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/saveGraphVisstat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves Graphical Output — saveGraphVisstat","text":"","code":"saveGraphVisstat(   fileName = NULL,   type = NULL,   fileDirectory = getwd(),   oldfile = NULL )"},{"path":"https://shhschilling.github.io/visStatistics/reference/saveGraphVisstat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves Graphical Output — saveGraphVisstat","text":"fileName name file created directory fileDirectory without file extension '.type'. type see Cairo(). fileDirectory path directory, graphic stored. Default setting current working directory. oldfile old file name overwritten","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/saveGraphVisstat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Saves Graphical Output — saveGraphVisstat","text":"NULL, type fileName provided, TRUE graph   created","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/saveGraphVisstat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Saves Graphical Output — saveGraphVisstat","text":"","code":"# very simple KDE (adapted from example in Cairo()) openGraphCairo(type = \"png\", fileDirectory = tempdir()) plot(rnorm(4000), rnorm(4000), col = \"#ff000018\", pch = 19, cex = 2) # save file 'norm.png' in directory specified in fileDirectory saveGraphVisstat(\"norm\", type = \"png\", fileDirectory = tempdir()) #> [1] TRUE file.remove(file.path(tempdir(), \"norm.png\")) # remove file 'norm.png' #> [1] TRUE"},{"path":"https://shhschilling.github.io/visStatistics/reference/vis_anova_assumptions.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualisation of the normality distribution of the standardised residuals of the ANOVA — vis_anova_assumptions","title":"Visualisation of the normality distribution of the standardised residuals of the ANOVA — vis_anova_assumptions","text":"vis_anova_assumptions checks normality standardised residuals ANOVA. Shapiro-Wilk test shapiro.test() Anderson-Darling test ad.test() check null standardised residuals normally distributed. generates scatter plot standardised residuals versus fitted mean values linear models level fact. Furthermore normal QQ plot standardised residuals generated. null homogeneity variances  factor level tested bartlett.test().","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/vis_anova_assumptions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualisation of the normality distribution of the standardised residuals of the ANOVA — vis_anova_assumptions","text":"","code":"vis_anova_assumptions(   samples,   fact,   conf.level = 0.95,   samplename = \"\",   factorname = \"\",   cex = 1 )"},{"path":"https://shhschilling.github.io/visStatistics/reference/vis_anova_assumptions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualisation of the normality distribution of the standardised residuals of the ANOVA — vis_anova_assumptions","text":"samples vector containing dependent variable, datatype numeric fact vector containing independent variable, datatype factor conf.level confidence level, 0.95=default samplename name sample used graphical output, dataype character , ”=default factorname name sample used graphical output, dataype character, ”=default cex number indicating amount plotting text symbols scaled relative default. 1=default, 1.5 50% larger, 0.5 50% smaller, etc.","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/vis_anova_assumptions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualisation of the normality distribution of the standardised residuals of the ANOVA — vis_anova_assumptions","text":"list containing test statistics anova, p values   generated Shapiro-Wilk test shapiro.test(),   Anderson-Darling test ad.test() bartlett.test().","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/vis_anova_assumptions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualisation of the normality distribution of the standardised residuals of the ANOVA — vis_anova_assumptions","text":"","code":"ToothGrowth$dose <- as.factor(ToothGrowth$dose) vis_anova_assumptions(ToothGrowth$len, ToothGrowth$dose)  #> $summary_anova #>             Df Sum Sq Mean Sq F value   Pr(>F)     #> fact         2   2426    1213   67.42 9.53e-16 *** #> Residuals   57   1026      18                      #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $shapiro_test #>  #> \tShapiro-Wilk normality test #>  #> data:  rstandard(anova) #> W = 0.96731, p-value = 0.1076 #>  #>  #> $ad_test #>  #> \tAnderson-Darling normality test #>  #> data:  rstandard(anova) #> A = 0.68679, p-value = 0.06928 #>  #>  #> $bartlett_test #>  #> \tBartlett test of homogeneity of variances #>  #> data:  samples by fact #> Bartlett's K-squared = 0.66547, df = 2, p-value = 0.717 #>  #>   vis_anova_assumptions(ToothGrowth$len, ToothGrowth$supp)  #> $summary_anova #>             Df Sum Sq Mean Sq F value Pr(>F)   #> fact         1    205  205.35   3.668 0.0604 . #> Residuals   58   3247   55.98                  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $shapiro_test #>  #> \tShapiro-Wilk normality test #>  #> data:  rstandard(anova) #> W = 0.96949, p-value = 0.1378 #>  #>  #> $ad_test #>  #> \tAnderson-Darling normality test #>  #> data:  rstandard(anova) #> A = 0.51449, p-value = 0.185 #>  #>  #> $bartlett_test #>  #> \tBartlett test of homogeneity of variances #>  #> data:  samples by fact #> Bartlett's K-squared = 1.4217, df = 1, p-value = 0.2331 #>  #>  vis_anova_assumptions(iris$Petal.Width, iris$Species)  #> $summary_anova #>              Df Sum Sq Mean Sq F value Pr(>F)     #> fact          2  80.41   40.21     960 <2e-16 *** #> Residuals   147   6.16    0.04                    #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $shapiro_test #>  #> \tShapiro-Wilk normality test #>  #> data:  rstandard(anova) #> W = 0.97217, p-value = 0.003866 #>  #>  #> $ad_test #>  #> \tAnderson-Darling normality test #>  #> data:  rstandard(anova) #> A = 1.8447, p-value = 9.831e-05 #>  #>  #> $bartlett_test #>  #> \tBartlett test of homogeneity of variances #>  #> data:  samples by fact #> Bartlett's K-squared = 39.213, df = 2, p-value = 3.055e-09 #>  #>"},{"path":"https://shhschilling.github.io/visStatistics/reference/visstat.html","id":null,"dir":"Reference","previous_headings":"","what":"Automated Visualization of Statistical Hypothesis Testing — visstat","title":"Automated Visualization of Statistical Hypothesis Testing — visstat","text":"visstat() provides automated selection visualization statistical hypothesis test response feature variable given data.frame named dataframe based data's type, distribution, sample size, specified conf.level. data dataframe must structured column-wise, varsample varfactor character strings corresponding column names response feature variables, respectively. automatically generated output figures illustrate selected statistical hypothesis test, display main test statistics, include assumption checks post hoc comparisons applicable. primary test results returned list object.","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/visstat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automated Visualization of Statistical Hypothesis Testing — visstat","text":"","code":"visstat(   dataframe,   varsample,   varfactor,   conf.level = 0.95,   numbers = TRUE,   minpercent = 0.05,   graphicsoutput = NULL,   plotName = NULL,   plotDirectory = getwd() )"},{"path":"https://shhschilling.github.io/visStatistics/reference/visstat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automated Visualization of Statistical Hypothesis Testing — visstat","text":"dataframe data.frame least two columns. varsample character string matching column name dataframe. Interpreted response referenced column class numeric integer column named varfactor class factor. varfactor character string matching column name dataframe. Interpreted grouping variable referenced column class factor column named varsample class numeric integer. conf.level Confidence level numbers logical indicating whether show numbers mosaic count plots. minpercent number 0 1 indicating minimal fraction total count data category displayed    mosaic count plots. graphicsoutput saves plot(s) type \"png\",  \"jpg\", \"tiff\"  \"bmp\" directory specified plotDirectory. graphicsoutput=NULL, plots saved. plotName graphical output stored following naming convention \"plotName.graphicsoutput\" plotDirectory. Without specifying parameter, plotName automatically generated following convention \"statisticalTestName_varsample_varfactor\". plotDirectory specifies directory, generated plots stored. Default current working directory.","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/visstat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automated Visualization of Statistical Hypothesis Testing — visstat","text":"list containing statistics automatically selected test   meeting assumptions. values returned invisible copies.   Values can accessed assigning return value visstat.","code":""},{"path":"https://shhschilling.github.io/visStatistics/reference/visstat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automated Visualization of Statistical Hypothesis Testing — visstat","text":"decision logic selecting statistical test described . details, please refer package's vignette(\"visStatistics\"). Throughout, data class numeric integer referred numerical, data class factor referred categorical. significance level alpha defined one minus confidence level, given argument conf.level. Assumptions normality homoscedasticity considered met corresponding test yields p-value greater alpha = 1 - conf.level. choice statistical tests performed visstat() depends whether data numerical categorical, number levels categorical variable, distribution data, chosen conf.level. function prioritises interpretable visual output tests remain valid assumptions, following logic : (1) response numerical predictor categorical, tests central tendency performed. predictor two levels: t.test() used groups 30 observations (Lumley et al. (2002) <doi:10.1146/annurev.publhealth.23.100901.140546>). smaller samples, normality assessed using shapiro.test(). groups return p-values greater alpha, t.test() applied; otherwise, wilcox.test() used. predictors two levels, aov() initially fitted. Residual normality tested shapiro.test() ad.test(). p > alpha either test, normality assumed. Homogeneity variance tested bartlett.test(). p > alpha, aov() TukeyHSD() used. p <= alpha, oneway.test() applied TukeyHSD(). residuals normal, kruskal.test() pairwise.wilcox.test() used. (2): response predictor numerical, linear model lm() fitted, residual diagnostics confidence band plot. (3): variables categorical, visstat() uses chisq.test() fisher.test() depending expected counts, following Cochran's rule (Cochran (1954) <doi:10.2307/3001666>). Implemented main tests: t.test(), wilcox.test(), aov(), oneway.test(), lm(), kruskal.test(), fisher.test(), chisq.test(). Implemented tests assumptions: Normality: shapiro.test() ad.test() Heteroscedasticity: bartlett.test() Implemented post hoc tests: TukeyHSD() aov() oneway.test() pairwise.wilcox.test() kruskal.test()","code":""},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/reference/visstat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automated Visualization of Statistical Hypothesis Testing — visstat","text":"","code":"# Welch Two Sample t-test (t.test()) visstat(mtcars, \"mpg\", \"am\")    ## Wilcoxon rank sum test (wilcox.test()) grades_gender <- data.frame(   Sex = as.factor(c(rep(\"Girl\", 20), rep(\"Boy\", 20))),   Grade = c(     19.3, 18.1, 15.2, 18.3, 7.9, 6.2, 19.4,     20.3, 9.3, 11.3, 18.2, 17.5, 10.2, 20.1, 13.3, 17.2, 15.1, 16.2, 17.3,     16.5, 5.1, 15.3, 17.1, 14.8, 15.4, 14.4, 7.5, 15.5, 6.0, 17.4,     7.3, 14.3, 13.5, 8.0, 19.5, 13.4, 17.9, 17.7, 16.4, 15.6   ) ) visstat(grades_gender, \"Grade\", \"Sex\")   ## Welch's oneway ANOVA not assuming equal variances (oneway.test()) anova_npk <- visstat(npk, \"yield\", \"block\")   anova_npk # prints summary of tests #> $`summary statistics of Fisher's one-way ANOVA` #>             Df Sum Sq Mean Sq F value Pr(>F)   #> fact         5  343.3   68.66   2.318 0.0861 . #> Residuals   18  533.1   29.61                  #> --- #> Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 #>  #> $`summary statistics of Welch's one-way ANOVA (not assuming equal variances)` #>  #> \tOne-way analysis of means (not assuming equal variances) #>  #> data:  samples and fact #> F = 6.2463, num df = 5.0000, denom df = 8.0508, p-value = 0.01178 #>  #>  #> $`adjusted p values from` #>   Tukey multiple comparisons of means #>     95% family-wise confidence level #>  #> Fit: aov(formula = samples ~ fact) #>  #> $fact #>        diff        lwr       upr     p adj #> 2-1   3.425  -8.804242 15.654242 0.9440575 #> 3-1   6.750  -5.479242 18.979242 0.5166401 #> 4-1  -3.900 -16.129242  8.329242 0.9074049 #> 5-1  -3.500 -15.729242  8.729242 0.9390165 #> 6-1   2.325  -9.904242 14.554242 0.9893559 #> 3-2   3.325  -8.904242 15.554242 0.9503518 #> 4-2  -7.325 -19.554242  4.904242 0.4312574 #> 5-2  -6.925 -19.154242  5.304242 0.4900643 #> 6-2  -1.100 -13.329242 11.129242 0.9996936 #> 4-3 -10.650 -22.879242  1.579242 0.1094850 #> 5-3 -10.250 -22.479242  1.979242 0.1321421 #> 6-3  -4.425 -16.654242  7.804242 0.8539828 #> 5-4   0.400 -11.829242 12.629242 0.9999980 #> 6-4   6.225  -6.004242 18.454242 0.5981409 #> 6-5   5.825  -6.404242 18.054242 0.6604328 #>  #>  #> $conf.level #> [1] 0.95 #>   ## Kruskal-Wallis rank sum test (kruskal.test()) visstat(iris, \"Petal.Width\", \"Species\")   visstat(InsectSprays, \"count\", \"spray\")  #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties #> Warning: cannot compute exact p-value with ties   ## Linear regression  (lm()) visstat(trees, \"Girth\", \"Height\", conf.level = 0.99)    ## Pearson's Chi-squared test (chisq.test()) ### Transform array to data.frame HairEyeColorDataFrame <- counts_to_cases(as.data.frame(HairEyeColor)) visstat(HairEyeColorDataFrame, \"Hair\", \"Eye\")    ## Fisher's exact test (fisher.test()) HairEyeColorMaleFisher <- HairEyeColor[, , 1] ### slicing out a 2 x2 contingency table blackBrownHazelGreen <- HairEyeColorMaleFisher[1:2, 3:4] blackBrownHazelGreen <- counts_to_cases(as.data.frame(blackBrownHazelGreen)) fisher_stats <- visstat(blackBrownHazelGreen, \"Hair\", \"Eye\")   fisher_stats # print out summary statistics #> $p.value #> [1] 0.503545 #>  #> $conf.int #> [1] 0.07725895 2.40885255 #> attr(,\"conf.level\") #> [1] 0.95 #>  #> $estimate #> odds ratio  #>  0.5062015  #>  #> $null.value #> odds ratio  #>          1  #>  #> $alternative #> [1] \"two.sided\" #>  #> $method #> [1] \"Fisher's Exact Test for Count Data\" #>  #> $data.name #> [1] \"counts\" #>  #> $mosaic_stats #>       Hair Brown Black #> Eye                    #> Hazel         25    10 #> Green         15     3 #>   ## Saving the graphical output in directory \"plotDirectory\" ## A) Saving graphical output of type \"png\" in temporary directory tempdir() ##    with default naming convention: visstat(blackBrownHazelGreen, \"Hair\", \"Eye\",   graphicsoutput = \"png\",   plotDirectory = tempdir() )  ## Remove graphical output from plotDirectory file.remove(file.path(tempdir(), \"chi_squared_or_fisher_Hair_Eye.png\")) #> [1] TRUE file.remove(file.path(tempdir(), \"mosaic_complete_Hair_Eye.png\")) #> [1] TRUE  ## B) Specifying pdf as output type: visstat(iris, \"Petal.Width\", \"Species\",   graphicsoutput = \"pdf\",   plotDirectory = tempdir() )  ## Remove graphical output from plotDirectory file.remove(file.path(tempdir(), \"kruskal_Petal_Width_Species.pdf\")) #> [1] TRUE  ## C) Specifying \"plotName\" overwrites default naming convention visstat(iris, \"Petal.Width\", \"Species\",   graphicsoutput = \"pdf\",   plotName = \"kruskal_iris\", plotDirectory = tempdir() ) ## Remove graphical output from plotDirectory file.remove(file.path(tempdir(), \"kruskal_iris.pdf\")) #> [1] TRUE"},{"path":[]},{"path":"https://shhschilling.github.io/visStatistics/news/index.html","id":"news-0-1-5","dir":"Changelog","previous_headings":"","what":"News","title":"visStatistics 0.1.5","text":"Extended vignette: implemented tests explained greater detail. Graphical output displays corresponding test statistics, addition p-values, appropriate. Internal helper function get_samples_fact_inputfile() longer exported NAMESPACE.","code":""},{"path":"https://shhschilling.github.io/visStatistics/news/index.html","id":"bug-fixes-0-1-5","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"visStatistics 0.1.5","text":"legend Šidák-corrected confidence interval longer incorrectly states displays group means.","code":""},{"path":"https://shhschilling.github.io/visStatistics/news/index.html","id":"visstatistics-013","dir":"Changelog","previous_headings":"","what":"visStatistics 0.1.3","title":"visStatistics 0.1.3","text":"CRAN release: 2025-05-12","code":""},{"path":"https://shhschilling.github.io/visStatistics/news/index.html","id":"news-0-1-3","dir":"Changelog","previous_headings":"","what":"News","title":"visStatistics 0.1.3","text":"Added vignette visStatistics.Rmd documenting statistical decision logic, reproducible examples illustrating test case. Added graphical summary decision logic README vignette.","code":""},{"path":"https://shhschilling.github.io/visStatistics/news/index.html","id":"improvements-0-1-3","dir":"Changelog","previous_headings":"","what":"Improvements","title":"visStatistics 0.1.3","text":"precise parameter descriptions. Clearer presentation decision logic.","code":""},{"path":"https://shhschilling.github.io/visStatistics/news/index.html","id":"change-in-decision-logic-0-1-3","dir":"Changelog","previous_headings":"","what":"Change in decision logic","title":"visStatistics 0.1.3","text":"Welch’s t-test (t.test()) now applied groups 30 observations (previous threshold 100).","code":""},{"path":"https://shhschilling.github.io/visStatistics/news/index.html","id":"bug-fixes-0-1-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"visStatistics 0.1.3","text":"Confidence prediction bands regression now correctly reflect specified conf.level rather defaulting 0.95. Post hoc analysis Kruskal–Wallis test (pairwise.wilcox.test()) now uses specified conf.level. Switching fisher.test() now correctly follows expected cell count thresholds.","code":""}]
