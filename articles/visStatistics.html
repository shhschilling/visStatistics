<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>visStatistics • visStatistics</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="visStatistics">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">visStatistics</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.4</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/visStatistics.html">Vignette</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/index.html">Articles</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/shhschilling/visStatistics/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>visStatistics</h1>
                        <h4 data-toc-skip class="author">Sabine
Schilling</h4>
            
            <h4 data-toc-skip class="date">2025-05-22</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/shhschilling/visStatistics/blob/master/vignettes/visStatistics.Rmd" class="external-link"><code>vignettes/visStatistics.Rmd</code></a></small>
      <div class="d-none name"><code>visStatistics.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/shhschilling/visStatistics" class="external-link">visStatistics</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><code>visStatistics</code> automatically selects and visualises
appropriate statistical hypothesis tests between a response and a
feature variable in a data frame. The choice of test depends on the
<code>class</code>, distribution, and sample size of the input
variables, as well as the user-defined ‘conf.level’. The main function
<code><a href="../reference/visstat.html">visstat()</a></code> visualises the selected test with appropriate
graphs (box plots, bar charts, regression lines with confidence bands,
mosaic plots, residual plots, Q-Q plots), annotated with the main test
results, including any assumption checks and post-hoc analyses. A
minimal function call looks like:</p>
<p><code>visstat(dataframe, varsample = "response", varfactor = "feature")</code></p>
<p>The input <code>data.frame</code> must be column-based, and the
response <code>varsample</code> and feature <code>varfactor</code> must
be character strings naming columns of the <code>data.frame</code>.</p>
<p>This scripted workflow is particularly suited for browser-based
interfaces that rely on server-side R applications connected to secure
databases, where users have no direct access, or for quick data
visualisations, e.g., in statistical consulting projects.</p>
<p>This scripted workflow is particularly well suited for interactive
interfaces where users access data only through a graphical front end
backed by server-side R sessions, as well as for quick data exploration
e.g. in statistical consulting contexts.</p>
<p>The remainder of this vignette is organised as follows:</p>
<ul>
<li><p>Section 2 summarises the decision logic of choosing a statistical
test, whilst</p></li>
<li><p>Sections 3 - 5 give background on the implemented tests and
visualises the decision logic using examples,</p></li>
<li><p>Section 6 gives an overview of the implemented tests.</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="decision-logic">Decision logic<a class="anchor" aria-label="anchor" href="#decision-logic"></a>
</h2>
<p>Throughout the remainder, data of class <code>"numeric"</code> or
<code>"integer"</code> are referred as numerical, while data of class
<code>"factor"</code> are referred to as categorical. The significance
level
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
used throughout for hypothesis testing, is defined as
<code>1 - conf.level</code>, where <code>conf.level</code> is a
user-controllable argument (defaulting to <code>0.95</code>).</p>
<p>The choice of statistical tests performed by the function
<code><a href="../reference/visstat.html">visstat()</a></code> depends on whether the data are numerical or
categorical, the number of levels in the categorical variable, the
distribution of the data, as well as the user-defined ‘conf.level’.</p>
<p>The function prioritizes interpretable visual output and tests that
remain valid under the following decision logic:</p>
<div class="section level3">
<h3 id="numerical-response-and-categorical-predictor">Numerical response and categorical predictor<a class="anchor" aria-label="anchor" href="#numerical-response-and-categorical-predictor"></a>
</h3>
<p>When the response is numerical and the predictor is categorical, a
statistical hypothesis test of central tendencies is selected.</p>
<ul>
<li><p>If the categorical predictor has exactly two levels, Welch’s
t-test (<code><a href="https://rdrr.io/r/stats/t.test.html" class="external-link">t.test()</a></code>) is applied whenever both groups contain
more than 30 observations, with the validity of the test supported by
the approximate normality of the sampling distribution of the mean under
the central limit theorem <span class="citation">Lumley et al.
(2002)</span>. For smaller samples, group - wise normality is assessed
using the Shapiro - Wilk test (<code><a href="https://rdrr.io/r/stats/shapiro.test.html" class="external-link">shapiro.test()</a></code>) at the
significance level
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.
If both groups are found to be approximately normally distributed
according to the Shapiro–Wilk test, Welch’s t-test is applied;
otherwise, the Wilcoxon rank-sum test (<code><a href="https://rdrr.io/r/stats/wilcox.test.html" class="external-link">wilcox.test()</a></code>) is
used.</p></li>
<li><p>For predictors with more than two levels, a model of Fisher’s
one-way analysis of variables (ANOVA) (<code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code>) is initially
fitted. The normality of residuals is evaluated using both the
Shapiro–Wilk test (<code><a href="https://rdrr.io/r/stats/shapiro.test.html" class="external-link">shapiro.test()</a></code>) and the Anderson-Darling
test (<code>ad.test()</code>); residuals are considered approximately
normal if at least one of the two tests yields a result exceeding the
significance threshold
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.
If this condition is met, Bartlett’s test (<code><a href="https://rdrr.io/r/stats/bartlett.test.html" class="external-link">bartlett.test()</a></code>)
assesses homoscedasticity. When variances are homogeneous
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&gt;</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">p &gt; \alpha</annotation></semantics></math>),
Fisher’s one-way ANOVA (<code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code>) is applied with Tukey’s
Honestly Significant Differences (HSD) (<code><a href="https://rdrr.io/r/stats/TukeyHSD.html" class="external-link">TukeyHSD()</a></code>) for
post-hoc comparison. If variances differ significantly
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≤</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">p \le \alpha</annotation></semantics></math>),
Welch’s heteroscedastic one-way ANOVA (<code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code>) is
used, also followed by Tukey’s HSD. If residuals are not normally
distributed according to both tests
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≤</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">p \le \alpha</annotation></semantics></math>),
the Kruskal–Wallis test (<code><a href="https://rdrr.io/r/stats/kruskal.test.html" class="external-link">kruskal.test()</a></code>) is selected,
followed by pairwise Wilcoxon tests
(<code><a href="https://rdrr.io/r/stats/pairwise.wilcox.test.html" class="external-link">pairwise.wilcox.test()</a></code>). A graphical overview of the
decision logic used is provided in the figure below.</p></li>
</ul>
<div style="border: 1px solid #666; padding: 10px; display: inline-block; text-align: center;">
<img src="../reference/figures/decision_tree.png" width="100%" alt="Decision tree used to select the appropriate statistical test."><p style="font-style: italic; font-size: 90%; margin-top: 0.5em;">
Decision tree used to select the appropriate statistical test for a
categorical predictor and numerical response, based on the number of
factor levels, normality, and homoscedasticity.
</p>
</div>
</div>
<div class="section level3">
<h3 id="numerical-response-and-numerical-feature">Numerical response and numerical feature<a class="anchor" aria-label="anchor" href="#numerical-response-and-numerical-feature"></a>
</h3>
<p>When both the response and predictor are numeric, a simple linear
regression model (<code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code>) is fitted and analysed in detail,
including residual diagnostics, formal tests, and the plotting of fitted
values with confidence bands. Note that <strong>only one</strong>
predictor variable is allowed, as the function is designed for
two-dimensional visualisation.</p>
</div>
<div class="section level3">
<h3 id="categorical-response-and-categorical-feature">Categorical response and categorical feature<a class="anchor" aria-label="anchor" href="#categorical-response-and-categorical-feature"></a>
</h3>
<p>In the case of two categorical variables, <code><a href="../reference/visstat.html">visstat()</a></code>
tests the null hypothesis that the predictor and response variables are
independent using either Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>-test
(<code><a href="https://rdrr.io/r/stats/chisq.test.html" class="external-link">chisq.test()</a></code>) or Fisher’s exact test
(<code><a href="https://rdrr.io/r/stats/fisher.test.html" class="external-link">fisher.test()</a></code>). The choice of test is based on Cochran’s
rule <span class="citation">(Cochran 1954)</span>, which advises that
the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>approximation
is reliable only if no expected cell count is less than 1 and no more
than 20 percent of cells have expected counts below 5.</p>
</div>
<div class="section level3">
<h3 id="limitations">Limitations<a class="anchor" aria-label="anchor" href="#limitations"></a>
</h3>
<p>The main purpose of this package is a decision-logic based automatic
visualisation of statistical test results. Therefore, except for the
user-adjustable <code>conf.level</code> parameter, all statistical tests
are applied using their default settings from the corresponding base R
functions. As a consequence, paired tests are currently not supported
and <code><a href="../reference/visstat.html">visstat()</a></code> does not allow to study interactions terms
between the different levels of an independent variable in an analysis
of variance. Focusing on the graphical representation of tests, only
simple linear regression is implemented, as multiple linear regressions
cannot be visualised.</p>
</div>
</div>
<div class="section level2">
<h2 id="numerical-response-and-categorical-feature">Numerical response and categorical feature<a class="anchor" aria-label="anchor" href="#numerical-response-and-categorical-feature"></a>
</h2>
<p>If the feature consists of <code>class</code> “<code>factor</code>”
with two or more levels and the response is of <code>class</code>
“<code>numeric</code>” or “<code>integer</code>” (both having mode
“<code>numerical</code>”), statistical tests are applied to compare the
central tendencies across groups. This section describes the conditions
under which parametric and non-parametric tests are chosen, based on the
response type, the number of factor levels, and the underlying
distributional assumptions.</p>
<div class="section level3">
<h3 id="categorical-feature-with-two-levels-welchs-t-test-and-wilcoxon-rank-sum-test">Categorical feature with two levels: Welch’s t-test and Wilcoxon
rank-sum test<a class="anchor" aria-label="anchor" href="#categorical-feature-with-two-levels-welchs-t-test-and-wilcoxon-rank-sum-test"></a>
</h3>
<p>When the feature variable has exactly two levels, Welch’s t-test or
the Wilcoxon rank-sum test is applied.</p>
<div class="section level4">
<h4 id="welchs-t-test-t-test">Welch’s t-test (<code>t.test()</code>)<a class="anchor" aria-label="anchor" href="#welchs-t-test-t-test"></a>
</h4>
<p>Welch’s t-test (<code><a href="https://rdrr.io/r/stats/t.test.html" class="external-link">t.test()</a></code>) assumes that the observations
are independent and that the response variable is approximately normally
distributed within each group. In contrast to Student’s t-test, it does
not require the assumption of equal variances (homoscedasticity) between
groups. Welch’s t-test remains valid and exhibits only minimal loss of
efficiency even when the assumptions of Student’s t-test – namely,
normality and equal variances of the response variable across groups –
are satisfied <span class="citation">(Moser and Stevens 1992; Delacre,
Lakens, and Leys 2017)</span>. Therefore, Student’s t-test is not
implemented.</p>
<p>Welch’s t-test evaluates the null hypothesis that the means of two
groups are equal without assuming equal variances. The test statistic is
given by <span class="citation">(Welch 1947; Satterthwaite
1946)</span></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mfrac><mrow><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mn>1</mn></msub><mo>−</mo><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mn>2</mn></msub></mrow><msqrt><mrow><mfrac><msubsup><mi>s</mi><mn>1</mn><mn>2</mn></msubsup><msub><mi>n</mi><mn>1</mn></msub></mfrac><mo>+</mo><mfrac><msubsup><mi>s</mi><mn>2</mn><mn>2</mn></msubsup><msub><mi>n</mi><mn>2</mn></msub></mfrac></mrow></msqrt></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex">
t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}},
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mn>1</mn></msub><annotation encoding="application/x-tex">\bar{x}_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mn>2</mn></msub><annotation encoding="application/x-tex">\bar{x}_2</annotation></semantics></math>
are the sample means,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>s</mi><mn>1</mn><mn>2</mn></msubsup><annotation encoding="application/x-tex">s_1^2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>s</mi><mn>2</mn><mn>2</mn></msubsup><annotation encoding="application/x-tex">s_2^2</annotation></semantics></math>
the sample variances, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>1</mn></msub><annotation encoding="application/x-tex">n_1</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>2</mn></msub><annotation encoding="application/x-tex">n_2</annotation></semantics></math>
the sample sizes in the two groups. The statistic follows a
<em>t</em>-distribution with degrees of freedom approximated by the
Welch-Satterthwaite equation:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ν</mi><mo>≈</mo><mfrac><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><msubsup><mi>s</mi><mn>1</mn><mn>2</mn></msubsup><msub><mi>n</mi><mn>1</mn></msub></mfrac><mo>+</mo><mfrac><msubsup><mi>s</mi><mn>2</mn><mn>2</mn></msubsup><msub><mi>n</mi><mn>2</mn></msub></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mrow><mfrac><msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>s</mi><mn>1</mn><mn>2</mn></msubsup><mi>/</mi><msub><mi>n</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>−</mo><mn>1</mn></mrow></mfrac><mo>+</mo><mfrac><msup><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>s</mi><mn>2</mn><mn>2</mn></msubsup><mi>/</mi><msub><mi>n</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mrow><msub><mi>n</mi><mn>2</mn></msub><mo>−</mo><mn>1</mn></mrow></mfrac></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
\nu \approx \frac{
  \left( \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2} \right)^2
}{
  \frac{(s_1^2 / n_1)^2}{n_1 - 1} + \frac{(s_2^2 / n_2)^2}{n_2 - 1}
}.
</annotation></semantics></math></p>
<p>The resulting p-value is computed from the <em>t</em>-distribution
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ν</mi><annotation encoding="application/x-tex">\nu</annotation></semantics></math>
degrees of freedom.</p>
</div>
<div class="section level4">
<h4 id="wilcoxon-rank-sum-test-wilcox-test">Wilcoxon rank-sum test (<code>wilcox.test()</code>)<a class="anchor" aria-label="anchor" href="#wilcoxon-rank-sum-test-wilcox-test"></a>
</h4>
<p>The two-sample Wilcoxon rank-sum test (also known as the Mann-Whitney
test) is a non-parametric alternative that does not require the response
variable to be approximately normally distributed within each group. It
tests for a difference in location between two independent distributions
<span class="citation">(Wilcoxon 1945; Mann and Whitney 1947)</span>. If
the two groups have distributions that are sufficiently similar in shape
and scale, the Wilcoxon rank-sum test can be interpreted as testing
whether the medians of the two populations are equal <span class="citation">(Hollander, Chicken, and Wolfe 2014)</span>.</p>
<p>The two-level factor variable <code>varfactor</code> defines two
groups, with sample sizes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>1</mn></msub><annotation encoding="application/x-tex">n_1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>2</mn></msub><annotation encoding="application/x-tex">n_2</annotation></semantics></math>.
All
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>+</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">n_1 + n_2</annotation></semantics></math>
observations are pooled and assigned ranks from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>
to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>+</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">n_1 + n_2</annotation></semantics></math>.
Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mtext mathvariant="normal">Wilcoxon</mtext></msub><annotation encoding="application/x-tex">W_{\text{Wilcoxon}}</annotation></semantics></math>
denote the sum of the ranks assigned to the group corresponding to the
first level of <code>varfactor</code> containing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mn>1</mn></msub><annotation encoding="application/x-tex">n_1</annotation></semantics></math>
observations. The test statistic returned by <code><a href="../reference/visstat.html">visstat()</a></code> is
then computed as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>=</mo><msub><mi>W</mi><mtext mathvariant="normal">Wilcoxon</mtext></msub><mo>−</mo><mfrac><mrow><msub><mi>n</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>n</mi><mn>1</mn></msub><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mn>2</mn></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
W = W_{\text{Wilcoxon}} - \frac{n_1(n_1 + 1)}{2}.
</annotation></semantics></math></p>
<p>If both groups contain fewer than 50 observations and the data
contain no ties, the <em>p</em>-value is computed exactly. Otherwise, a
normal approximation with continuity correction is used.</p>
</div>
<div class="section level4">
<h4 id="graphical-output">Graphical output<a class="anchor" aria-label="anchor" href="#graphical-output"></a>
</h4>
<!-- The below paragph is a repetition of the decision logic:  -->
<!-- `visstat()` selects between Welch's t-test and the Wilcoxon rank-sum test as follows. If both groups contain more than 30 observations, Welch's t-test is always applied, relying on the central limit theorem to justify its application regardless of underlying normality [@Rasch:2011; @Lumley:2002]. -->
<!-- If either group contains fewer than 30 observations, the Shapiro--Wilk test (`shapiro.test()`) is applied separately to each group. Welch's t-test is used if both tests do not reject normality at the significance level $\alpha$; otherwise, the Wilcoxon rank-sum test is applied. -->
<p>The graphical output consists of box plots overlaid with jittered
points to display individual observations. When Welch’s t-test is
applied, the function includes confidence intervals based on the
user-specified <code>conf.level</code>.</p>
<p>The title is structured as follows:</p>
<ul>
<li><p>First line: Test name and chosen significance level
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</p></li>
<li><p>Second line: Null hypotheses automatically adapted based on the
user-specified <code>varsample</code> and
<code>varfactor</code>.</p></li>
<li><p>Third line: Test statistic, p-value and automated comparison with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></p></li>
</ul>
<p>The function returns a list containing the results of the applied
test and the summary statistics used to construct the plot.</p>
</div>
<div class="section level4">
<h4 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a>
</h4>
<div class="section level5">
<h5 class="unnumbered" id="welchs-t-test">Welch’s t-test<a class="anchor" aria-label="anchor" href="#welchs-t-test"></a>
</h5>
<p>The <em>Motor Trend Car Road Tests</em> dataset (<code>mtcars</code>)
contains 32 observations, where <code>mpg</code> denotes miles per (US)
gallon, and <code>am</code> represents the transmission type
(<code>0</code> = automatic, <code>1</code> = manual).</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mtcars</span><span class="op">$</span><span class="va">am</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">$</span><span class="va">am</span><span class="op">)</span></span>
<span><span class="va">t_test_statistics</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">mtcars</span>, <span class="st">"mpg"</span>, <span class="st">"am"</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-2-1.png" width="100%"></p>
<p>Increasing the confidence level <code>conf.level</code> from the
default 0.95 to 0.99 results in wider confidence intervals, as a higher
confidence level requires more conservative bounds to ensure that the
interval includes the true parameter value with greater certainty.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mtcars</span><span class="op">$</span><span class="va">am</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">mtcars</span><span class="op">$</span><span class="va">am</span><span class="op">)</span></span>
<span><span class="va">t_test_statistics_99</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">mtcars</span>, <span class="st">"mpg"</span>, <span class="st">"am"</span>, conf.level <span class="op">=</span> <span class="fl">0.99</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-3-1.png" width="100%"></p>
</div>
<div class="section level5">
<h5 class="unnumbered" id="wilcoxon-rank-sum-test">Wilcoxon rank sum test<a class="anchor" aria-label="anchor" href="#wilcoxon-rank-sum-test"></a>
</h5>
<p>The Wilcoxon rank sum test is exemplified on differences between the
central tendencies of grades of “boys” and “girls” in a class:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">grades_gender</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  sex <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"girl"</span>, <span class="fl">21</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">"boy"</span>, <span class="fl">23</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  grade <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="fl">19.3</span>, <span class="fl">18.1</span>, <span class="fl">15.2</span>, <span class="fl">18.3</span>, <span class="fl">7.9</span>, <span class="fl">6.2</span>, <span class="fl">19.4</span>,</span>
<span>    <span class="fl">20.3</span>, <span class="fl">9.3</span>, <span class="fl">11.3</span>, <span class="fl">18.2</span>, <span class="fl">17.5</span>, <span class="fl">10.2</span>, <span class="fl">20.1</span>, <span class="fl">13.3</span>, <span class="fl">17.2</span>, <span class="fl">15.1</span>, <span class="fl">16.2</span>, <span class="fl">17.0</span>,</span>
<span>    <span class="fl">16.5</span>, <span class="fl">5.1</span>, <span class="fl">15.3</span>, <span class="fl">17.1</span>, <span class="fl">14.8</span>, <span class="fl">15.4</span>, <span class="fl">14.4</span>, <span class="fl">7.5</span>, <span class="fl">15.5</span>, <span class="fl">6.0</span>, <span class="fl">17.4</span>,</span>
<span>    <span class="fl">7.3</span>, <span class="fl">14.3</span>, <span class="fl">13.5</span>, <span class="fl">8.0</span>, <span class="fl">19.5</span>, <span class="fl">13.4</span>, <span class="fl">17.9</span>, <span class="fl">17.7</span>, <span class="fl">16.4</span>, <span class="fl">15.6</span>, <span class="fl">17.3</span>, <span class="fl">19.9</span>, <span class="fl">4.4</span>, <span class="fl">2.1</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">wilcoxon_statistics</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">grades_gender</span>, <span class="st">"grade"</span>, <span class="st">"sex"</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-4-1.png" width="100%"></p>
</div>
</div>
</div>
<div class="section level3">
<h3 id="categorical-feature-with-more-than-two-levels">Categorical feature with more than two levels<a class="anchor" aria-label="anchor" href="#categorical-feature-with-more-than-two-levels"></a>
</h3>
<p>If the feature is of <code>class</code> “<code>factor</code>” with
<strong>more than two levels</strong> and the response is of
<code>mode</code> “<code>numerical</code>”, <code><a href="../reference/visstat.html">visstat()</a></code>
either performs Fisher’s one-way ANOVA <span class="citation">(Fisher
1971)</span> (<code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code>), Welch’s heteroscedastic one-way ANOVA
<span class="citation">(Welch 1951)</span> (<code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code>)
or, as a non-parametric alternative, the Kruskal–Wallis test <span class="citation">(Kruskal and Wallis 1952)</span>
(<code><a href="https://rdrr.io/r/stats/kruskal.test.html" class="external-link">kruskal.test()</a></code>).</p>
<p>In the remainder of this section, we briefly introduce the tests
themselves, the assumption checks, and the post-hoc procedures, and
illustrate each test with an example.</p>
<div class="section level4">
<h4 id="fishers-one-way-anova-aov">Fisher’s one-way ANOVA (<code>aov()</code>)<a class="anchor" aria-label="anchor" href="#fishers-one-way-anova-aov"></a>
</h4>
<p>Fisher’s one-way ANOVA (<code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code>) tests the null hypothesis
that the means of multiple groups are equal. It assumes independent
observations, normally distributed residuals, and
<strong>homogeneous</strong> variances across groups. The test statistic
is the ratio of the variance explained by differences among group means
(between-group variance) to the unexplained variance within groups:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo>=</mo><mfrac><mtext mathvariant="normal">between-group variance</mtext><mtext mathvariant="normal">within-group variance</mtext></mfrac><mo>=</mo><mfrac><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>n</mi><mi>i</mi></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mi>i</mi></msub><mo>−</mo><mover><mi>x</mi><mo accent="true">‾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></mfrac><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mi>i</mi></msub></munderover><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><mrow><mi>N</mi><mo>−</mo><mi>k</mi></mrow></mfrac></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex">
F = \frac{\text{between-group variance}}{\text{within-group variance}} 
  = \frac{\frac{\sum_{i=1}^{k} n_i (\bar{x}_i - \bar{x})^2}{k - 1}}
         {\frac{\sum_{i=1}^{k}\sum_{j=1}^{n_i}(x_{ij}-\bar{x}_i)^2}{N - k}},
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>x</mi><mo accent="true">‾</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\bar{x}_i</annotation></semantics></math>
is the mean of group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>x</mi><mo accent="true">‾</mo></mover><annotation encoding="application/x-tex">\bar{x}</annotation></semantics></math>
is the overall mean,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">x_{ij}</annotation></semantics></math>
is the observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
in group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mi>i</mi></msub><annotation encoding="application/x-tex">n_i</annotation></semantics></math>
is the sample size in group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
is the number of groups, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
is the total number of observations.</p>
<p>Under the null hypothesis, this statistic follows an F-distribution
with two parameters for degrees of freedom: the numerator
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k - 1</annotation></semantics></math>)
and the denominator
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>−</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">N - k</annotation></semantics></math>).
The resulting p-value is computed from this distribution.</p>
</div>
<div class="section level4">
<h4 id="welchs-heteroscedastic-one-way-anova-oneway-test">Welch’s heteroscedastic one-way ANOVA
(<code>oneway.test()</code>)<a class="anchor" aria-label="anchor" href="#welchs-heteroscedastic-one-way-anova-oneway-test"></a>
</h4>
<p>When only the assumptions of independent observations and normally
distributed residuals are met, but <em>homogeneous variances</em> across
groups <em>cannot be assumed</em> , Welch’s heteroscedastic one-way
ANOVA (<code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code>) <span class="citation">(Welch
1951)</span> provides an alternative to <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code>. It compares
group means using weights based on sample sizes and variances. The
degrees of freedom are adjusted using a Satterthwaite-type approximation
<span class="citation">(Satterthwaite 1946)</span>, resulting in an
F-statistic with non-integer degrees of freedom.</p>
</div>
<div class="section level4">
<h4 id="kruskalwallis-test-kruskal-test">Kruskal–Wallis test (<code>kruskal.test()</code>)<a class="anchor" aria-label="anchor" href="#kruskalwallis-test-kruskal-test"></a>
</h4>
<p>When the assumption of normality is not met, the Kruskal–Wallis test
provides a non-parametric alternative. It compares group distributions
based on ranked values and tests the null hypothesis that the groups
come from the same population — specifically, that the distributions
have the same location <span class="citation">(Kruskal and Wallis
1952)</span>. If the group distributions are sufficiently similar in
shape and scale, then the Kruskal–Wallis test can be interpreted as
testing for equality of medians across groups <span class="citation">(Hollander, Chicken, and Wolfe 2014)</span>.</p>
<p>The test statistic is defined as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>=</mo><mfrac><mn>12</mn><mrow><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><msub><mi>n</mi><mi>i</mi></msub><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>R</mi><mo accent="true">‾</mo></mover><mi>i</mi></msub><mo>−</mo><mover><mi>R</mi><mo accent="true">‾</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><mo>,</mo></mrow><annotation encoding="application/x-tex">
H = \frac{12}{N(N+1)} \sum_{i=1}^{k} n_i \left(\bar{R}_i - \bar{R} \right)^2,
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>n</mi><mi>i</mi></msub><annotation encoding="application/x-tex">n_i</annotation></semantics></math>
is the sample size in group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
is the number of groups,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>R</mi><mo accent="true">‾</mo></mover><mi>i</mi></msub><annotation encoding="application/x-tex">\bar{R}_i</annotation></semantics></math>
is the average rank of group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
is the total sample size, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>R</mi><mo accent="true">‾</mo></mover><mo>=</mo><mfrac><mrow><mi>N</mi><mo>+</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\bar{R} = \frac{N+1}{2}</annotation></semantics></math>
is the average of all ranks. Under the null hypothesis,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>H</mi><annotation encoding="application/x-tex">H</annotation></semantics></math>
approximately follows a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>
distribution with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k - 1</annotation></semantics></math>
degrees of freedom.</p>
</div>
<div class="section level4">
<h4 id="test-choice">Test choice<a class="anchor" aria-label="anchor" href="#test-choice"></a>
</h4>
</div>
<div class="section level4">
<h4 id="testing-the-assumptions-visanovaassumptions">Testing the assumptions (<code>visAnovaAssumptions()</code>)<a class="anchor" aria-label="anchor" href="#testing-the-assumptions-visanovaassumptions"></a>
</h4>
<p>The test logic for <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code> and <code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code>
follows from their respective assumptions. <code><a href="../reference/visstat.html">visstat()</a></code>
initially models the data using <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code> and analyses the
residuals.</p>
<p>If both of the following conditions are met: (1) the standardised
residuals follow a normal distribution, and (2) the residuals exhibit
homoscedasticity (equal variances across groups), then the test
statistic from <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code> is returned.</p>
<p>If only the normality assumption is satisfied, <code><a href="../reference/visstat.html">visstat()</a></code>
applies <code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code>. If the normality assumption is
violated, <code><a href="https://rdrr.io/r/stats/kruskal.test.html" class="external-link">kruskal.test()</a></code> is used instead.</p>
<p>These assumptions are tested using the
<code>visAnovaAssumptions()</code> function.</p>
<div class="section level5">
<h5 id="normality-of-residuals-shapiro-test-and-ad-test">Normality of residuals (<code>shapiro.test()</code> and
<code>ad.test()</code>)<a class="anchor" aria-label="anchor" href="#normality-of-residuals-shapiro-test-and-ad-test"></a>
</h5>
<p>The <code>visAnovaAssumptions()</code> function assesses the
normality of standardised residuals from the ANOVA fit using both the
Shapiro–Wilk test (<code><a href="https://rdrr.io/r/stats/shapiro.test.html" class="external-link">shapiro.test()</a></code>) and the Anderson–Darling
test (<code>ad.test()</code>). Normality is assumed if at least one of
the two tests yields a p-value greater than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.
<!-- (see Figure @ref(fig:fig-decision-tree)). --></p>
<p>The function generates two diagnostic plots:</p>
<ul>
<li>a scatter plot of the standardised residuals against the fitted
means of the linear model for each level of the feature
(<code>varfactor</code>), and</li>
<li>a Q–Q plot of the standardised residuals.</li>
</ul>
</div>
<div class="section level5">
<h5 id="equal-variances-across-groups-bartlett-test">Equal variances across groups (<code>bartlett.test()</code>)<a class="anchor" aria-label="anchor" href="#equal-variances-across-groups-bartlett-test"></a>
</h5>
<p>Both <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code> and <code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code> assess whether
two or more samples drawn from normal distributions have the same mean.
While <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code> assumes homogeneity of variances across groups,
<code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code> does not require the variances to be
equal.</p>
<p>Homoscedasticity is assessed using Bartlett’s test
(<code><a href="https://rdrr.io/r/stats/bartlett.test.html" class="external-link">bartlett.test()</a></code>), which tests the null hypothesis that the
variances across all levels of the grouping variable are equal.</p>
</div>
</div>
<div class="section level4">
<h4 id="controlling-the-family-wise-error-rate">Controlling the family-wise error rate<a class="anchor" aria-label="anchor" href="#controlling-the-family-wise-error-rate"></a>
</h4>
<p>After a significant test result, we would like to identify which
specific groups differ significantly from each other. However, simple
pairwise comparisons of group means or medians following an ANOVA or
Kruskal–Wallis test increase the probability of incorrectly declaring a
significant difference when, in fact, there is none.</p>
<p>This error is quantified by the family-wise error rate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mrow><mi>P</mi><mi>F</mi></mrow></msub><annotation encoding="application/x-tex">\alpha_{PF}</annotation></semantics></math>
(pronounced “alpha per family of tests”), which refers to the
probability of making at least one Type I error, that is, falsely
rejecting the null hypothesis across all pairwise comparisons.</p>
<p>Given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
levels of the categorical variable, there are</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>=</mo><mfrac><mrow><mi>n</mi><mo>⋅</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">
M = \frac{n \cdot (n - 1)}{2}
</annotation></semantics></math></p>
<p>pairwise comparisons possible, defining a <em>family of tests</em>
<span class="citation">(Abdi 2007)</span>.</p>
<div class="section level5">
<h5 class="unnumbered" id="šidák-correction">Šidák correction<a class="anchor" aria-label="anchor" href="#%C5%A1id%C3%A1k-correction"></a>
</h5>
<p>If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mrow><mi>P</mi><mi>T</mi></mrow></msub><annotation encoding="application/x-tex">\alpha_{PT}</annotation></semantics></math>
(pronounced “alpha per test”) is the probability of making a Type I
error in one comparison, then
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><msub><mi>α</mi><mrow><mi>P</mi><mi>T</mi></mrow></msub></mrow><annotation encoding="application/x-tex">1 - \alpha_{PT}</annotation></semantics></math>
is the probability of not making a Type I error in one comparison.</p>
<p>If all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
comparisons are <strong>independent</strong> of each other, the
probability of making no Type I error across the entire family of
pairwise comparisons is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>α</mi><mrow><mi>P</mi><mi>T</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>M</mi></msup><annotation encoding="application/x-tex">(1 - \alpha_{PT})^M</annotation></semantics></math>.
The family-wise error rate is then given by its complement <span class="citation">(Abdi 2007)</span>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>P</mi><mi>F</mi></mrow></msub><mo>=</mo><mn>1</mn><mo>−</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>α</mi><mrow><mi>P</mi><mi>T</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>M</mi></msup><mi>.</mi></mrow><annotation encoding="application/x-tex">
\alpha_{PF} = 1 - (1 - \alpha_{PT})^M.
</annotation></semantics></math></p>
<p>Let us illustrate the inflation of the family-wise error rate with
increasing group number
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
(equal to the number of <code>levels</code> in the categorical
variable)) by the following examples: With
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>P</mi><mi>T</mi></mrow></msub><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">\alpha_{PT}=0.05</annotation></semantics></math>
comparing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">n=3</annotation></semantics></math>
groups results in a family-wise error rate of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>P</mi><mi>F</mi></mrow></msub><mo>≈</mo><mn>14</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">\alpha_{PF} \approx 14\%</annotation></semantics></math>,
whereas comparing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">n=6</annotation></semantics></math>
groups (as in the examples below) already leads to the probability of at
least one time falsely rejecting the null hypothesis of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>P</mi><mi>F</mi></mrow></msub><mo>≈</mo><mn>54</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">\alpha_{PF} \approx 54\%</annotation></semantics></math>.</p>
<p>Solving the last equation defining
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mrow><mi>P</mi><mi>F</mi></mrow></msub><annotation encoding="application/x-tex">\alpha_{PF}</annotation></semantics></math>
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mrow><mi>P</mi><mi>T</mi></mrow></msub><annotation encoding="application/x-tex">\alpha_{PT}</annotation></semantics></math>
yields the Šidák equation <span class="citation">(Šidák
1967)</span>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>P</mi><mi>T</mi></mrow></msub><mo>=</mo><mn>1</mn><mo>−</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>α</mi><mrow><mi>P</mi><mi>F</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mn>1</mn><mi>/</mi><mi>M</mi></mrow></msup><mi>.</mi></mrow><annotation encoding="application/x-tex">
\alpha_{PT}=1-(1-{\alpha_{PF}})^{1/M}.
</annotation></semantics></math> This shows that, in order to achieve a
given family-wise error rate, the corresponding per-test significance
level must be reduced when there are more than two groups.
<!-- ###### Šidák  correction in `visstat()` {.unnumbered} --></p>
<p><code><a href="../reference/visstat.html">visstat()</a></code> sets
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mrow><mi>P</mi><mi>F</mi></mrow></msub><annotation encoding="application/x-tex">\alpha_{PF}</annotation></semantics></math>
to the user-defined
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>1</mn><mo>−</mo></mrow><annotation encoding="application/x-tex">\alpha = 1 -</annotation></semantics></math><code>conf.level</code>, resulting in</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>P</mi><mi>T</mi></mrow></msub><mo>=</mo><mn>1</mn><mo>−</mo><msup><mtext mathvariant="monospace">𝚌𝚘𝚗𝚏.𝚕𝚎𝚟𝚎𝚕</mtext><mrow><mn>1</mn><mi>/</mi><mi>M</mi></mrow></msup><mi>.</mi></mrow><annotation encoding="application/x-tex">
\alpha_{PT} = 1 - \texttt{conf.level}^{1 / M}.
</annotation></semantics></math></p>
<p>The Šidák approach becomes very conservative when the number of
comparisons is large or when the tests are not independent.</p>
</div>
<div class="section level5">
<h5 id="post-hoc-test-following-following-an-anova-tukeyhsd">Post-hoc-test following following an ANOVA: <code class="unnumbered">TukeyHSD()</code><a class="anchor" aria-label="anchor" href="#post-hoc-test-following-following-an-anova-tukeyhsd"></a>
</h5>
<p>The Šidák correction adjusts the significance level to control the
family-wise error rate for any set of independent comparisons, while
Tukey’s Honestly Significant Differences (<code><a href="https://rdrr.io/r/stats/TukeyHSD.html" class="external-link">TukeyHSD()</a></code>)
procedure applies this control specifically to all pairwise mean
comparisons after an ANOVA (either <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code> or
<code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code>), using a critical value derived from the
studentised range distribution.</p>
<p>Based on the user-specified confidence level
(<code>conf.level</code>), confidence intervals are constructed for all
pairwise differences between factor level means. A significant
difference between two means is indicated when the corresponding
confidence interval does not include zero. <code><a href="../reference/visstat.html">visstat()</a></code>
returns both the HSD-adjusted p-values and the associated confidence
intervals for all pairwise comparisons.</p>
</div>
<div class="section level5">
<h5 class="unnumbered" id="post-hoc-test-following-the-kruskalwallis-rank-sum-test-pairwise-wilcox-test">Post-hoc-test following the Kruskal–Wallis rank
sum test: <code>pairwise.wilcox.test()</code><a class="anchor" aria-label="anchor" href="#post-hoc-test-following-the-kruskalwallis-rank-sum-test-pairwise-wilcox-test"></a>
</h5>
<!-- If the p-value from the Shapiro--Wilk test (`shapiro.test()`) applied to the standardised residuals is smaller than the significance level $\alpha$, `visstat()` selects as non-parametric alternative: the Kruskal--Wallis rank sum test. -->
<p>As a post-hoc analysis following the Kruskal–Wallis test,
<code><a href="../reference/visstat.html">visstat()</a></code> applies the pairwise Wilcoxon rank sum test using
<code><a href="https://rdrr.io/r/stats/pairwise.wilcox.test.html" class="external-link">pairwise.wilcox.test()</a></code> with Holm’s method <span class="citation">(Holm 1979)</span> as the default adjustment for
multiple comparisons. Holm’s procedure is also much less stringent than
the Šidák method.</p>
<!-- #### Post-hoc test visualisation -->
<!-- In the graphical output, green letters displayed below each group summarise the results of the relevant post-hoc test:  Two groups are considered significantly different if they are assigned different letters, indicating a Tukey HSD-adjusted or Holm's-adjusted pairwise Wilcoxon rank sum test are  -->
<!--  p-value smaller than $\alpha$. -->
<!-- If the Holm-adjusted p-value for a given pair of groups is smaller than the significance level $\alpha$, the green letters displayed below the corresponding box plots will differ. Otherwise, the groups are considered not significantly different. -->
<!-- ### Graphical output -->
<!-- ####  {.unnumbered} -->
<!-- Depending on the p-value returned by `bartlett.test()`, the corresponding test is selected and its p-value is displayed in the figure title: -->
<!-- -   If the p-value of `bartlett.test()` is greater than $\alpha$, we assume homogeneity of variances across groups and report the p-value from the analysis of variance (ANOVA) implemented as(`aov()`). -->
<!-- -   Otherwise, homoscedasticity cannot be assumed, and the function reports the p-value from Welch's one-way test (`oneway.test()`). -->
</div>
</div>
<div class="section level4">
<h4 id="graphical-output-1">Graphical output<a class="anchor" aria-label="anchor" href="#graphical-output-1"></a>
</h4>
<p>The graphical output for all tests based on a numerical response and
a categorical feature with more than two levels consists of two panels:
the first focuses on the residual analysis, and the second on the actual
test chosen by the decision logic.</p>
<p>The residual panel addresses the assumption of normality, both
graphically and through formal tests. It displays a scatter plot of the
standardised residuals versus the fitted mean values, as well as a
normal Q–Q plot comparing the sample quantiles to the theoretical
quantiles. If the residuals are normally distributed, no more than
approximately
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">5\%</annotation></semantics></math>
of the standardised residuals should exceed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">|</mo><mn>2</mn><mo stretchy="true" form="postfix">|</mo></mrow><annotation encoding="application/x-tex">|2|</annotation></semantics></math>
and in the Q–Q plot the data points should approximately follow the red
straight line.</p>
<p>To assume normality of residuals, the formal tests for normality
(Shapiro–Wilk and Anderson–Darling) should result in p-values greater
than the user-defined
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</p>
<p>To assume homogeneity of variances, Bartlett’s test (shown in the
first line of the panel title) should also result in a p-value greater
than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</p>
<p><code><a href="../reference/visstat.html">visstat()</a></code> then illustrates, in the subsequent graph,
either the <code><a href="https://rdrr.io/r/stats/kruskal.test.html" class="external-link">kruskal.test()</a></code>, the <code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code>,
or <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code> result (see Section “Decision logic”).</p>
<p>If neither normality of the residuals nor homogeneity of variances is
given, the <code><a href="https://rdrr.io/r/stats/kruskal.test.html" class="external-link">kruskal.test()</a></code> is executed. The result is
illustrated using box plots alongside jittered data points, with the
title displaying the p-value from <code><a href="https://rdrr.io/r/stats/kruskal.test.html" class="external-link">kruskal.test()</a></code>.</p>
<p>Above each box plot, the number of observations per level is shown.
Different green letters below a pair of box plots indicate that the two
groups are considered significantly different, based on Holm’s-adjusted
pairwise Wilcoxon rank sum test p-values smaller than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</p>
<p>If normality of the residuals can be assumed, a parametric test is
chosen: either <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code>, if homoscedasticity is also assumed,
or <code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code> otherwise. <code><a href="../reference/visstat.html">visstat()</a></code> displays
the name of the test and the corresponding
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-value
in the title.</p>
<p>The graph shows both the <code>conf.level</code>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⋅</mo><mspace width="0.167em"></mspace><mn>100</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">\cdot\,100\%</annotation></semantics></math>
confidence intervals and the wider Šidák-corrected
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><msub><mi>α</mi><mrow><mi>P</mi><mi>T</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>⋅</mo><mn>100</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">(1 - \alpha_{PT}) \cdot 100\%</annotation></semantics></math>
confidence intervals, alongside jittered data points for each group.</p>
<p>Different green letters below a pair of confidence intervals indicate
that the two groups are considered significantly different, based on the
results of the <code><a href="https://rdrr.io/r/stats/TukeyHSD.html" class="external-link">TukeyHSD()</a></code> procedure.</p>
<p>The function returns a list containing the relevant test statistic
along with the post-hoc-adjusted
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>-values
for all pairwise comparisons.</p>
</div>
<div class="section level4">
<h4 id="examples-1">Examples<a class="anchor" aria-label="anchor" href="#examples-1"></a>
</h4>
<div class="section level5">
<h5 class="unnumbered" id="one-way-test">One-way test<a class="anchor" aria-label="anchor" href="#one-way-test"></a>
</h5>
<p>The <code>npk</code> dataset reports the yield of peas (in pounds per
block) from an agricultural experiment conducted on six blocks. In this
experiment, the application of three different fertilisers – nitrogen
(N), phosphate (P), and potassium (K) – was varied systematically. Each
block received either none, one, two, or all three of the
fertilisers,</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">oneway_npk</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">npk</span>, <span class="st">"yield"</span>, <span class="st">"block"</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-5-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-5-2.png" width="100%"></p>
<p>Normality of residuals is supported by graphical diagnostics (scatter
plot of standardised residuals, Q-Q plot) and formal tests (Shapiro–Wilk
and Anderson-Darling, both with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&gt;</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">p &gt; \alpha</annotation></semantics></math>).
However, homogeneity of variances is not supported at the given
confidence level
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&lt;</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">p &lt; \alpha</annotation></semantics></math>,
<code><a href="https://rdrr.io/r/stats/bartlett.test.html" class="external-link">bartlett.test()</a></code>), so the p-value from the variance-robust
<code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code> is reported. Post-hoc analysis with
<code><a href="https://rdrr.io/r/stats/TukeyHSD.html" class="external-link">TukeyHSD()</a></code> shows no significant yield differences between
blocks, as all share the same group label (e.g., all green letters).</p>
</div>
<div class="section level5">
<h5 class="unnumbered" id="anova-example">ANOVA example<a class="anchor" aria-label="anchor" href="#anova-example"></a>
</h5>
<!-- {.unnumbered} -->
<p>The <code>InsectSprays</code> dataset reports insect counts from
agricultural experimental units treated with six different insecticides.
To stabilise the variance in counts, we apply a square root
transformation to the response variable.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">insect_sprays_tr</span> <span class="op">&lt;-</span> <span class="va">InsectSprays</span></span>
<span><span class="va">insect_sprays_tr</span><span class="op">$</span><span class="va">count_sqrt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">InsectSprays</span><span class="op">$</span><span class="va">count</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">insect_sprays_tr</span>, <span class="st">"count_sqrt"</span>, <span class="st">"spray"</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-6-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-6-2.png" width="100%"></p>
<p>After the transformation, the homogeneity of variances can be assumed
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&gt;</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">p&gt; \alpha</annotation></semantics></math>
as calculated with the <code><a href="https://rdrr.io/r/stats/bartlett.test.html" class="external-link">bartlett.test()</a></code>), and the p-value of
the <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code> is displayed.</p>
</div>
<div class="section level5">
<h5 class="unnumbered" id="kruskalwallis-rank-sum-test">Kruskal–Wallis rank sum test<a class="anchor" aria-label="anchor" href="#kruskalwallis-rank-sum-test"></a>
</h5>
<p>The <code>iris</code> dataset contains petal width measurements (in
cm) for three different iris species.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">iris</span>, <span class="st">"Petal.Width"</span>, <span class="st">"Species"</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-7-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-7-2.png" width="100%"></p>
<p>In this example, scatter plots of the standardised residuals and the
Q-Q plot suggest that the residuals are not normally distributed. This
is confirmed by very small p-values from both the Shapiro–Wilk and
Anderson-Darling tests.</p>
<p>If both p-values are below the significance level
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
<code><a href="../reference/visstat.html">visstat()</a></code> switches to the non-parametric
<code><a href="https://rdrr.io/r/stats/kruskal.test.html" class="external-link">kruskal.test()</a></code>. Post-hoc analysis using
<code><a href="https://rdrr.io/r/stats/pairwise.wilcox.test.html" class="external-link">pairwise.wilcox.test()</a></code> shows significant differences in
petal width between all three species, as indicated by distinct group
labels (all green letters differ).</p>
</div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="numerical-response-and-numerical-feature-1">Numerical response and numerical feature<a class="anchor" aria-label="anchor" href="#numerical-response-and-numerical-feature-1"></a>
</h2>
<div class="section level3">
<h3 id="simple-linear-regression-lm">Simple linear regression (<code>lm()</code>)<a class="anchor" aria-label="anchor" href="#simple-linear-regression-lm"></a>
</h3>
<p>If both the feature <code>varfactor</code> and the response
<code>varsample</code> are numerical and contain only one level each,
<code><a href="../reference/visstat.html">visstat()</a></code> performs a simple linear regression.</p>
<p>The resulting regression plot displays the point estimate of the
regression line</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mo>⋅</mo><mi>x</mi><mo>,</mo></mrow><annotation encoding="application/x-tex">
y = a + b \cdot x,
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
is the response variable,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
is the feature variable,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>
is the intercept, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math>
is the slope of the regression line.</p>
<div class="section level4">
<h4 id="residual-analysis">Residual analysis<a class="anchor" aria-label="anchor" href="#residual-analysis"></a>
</h4>
<p><code><a href="../reference/visstat.html">visstat()</a></code> checks the normality of the standardised
residuals from <code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code> both graphically and using the
Shapiro–Wilk and Anderson-Darling tests. If the p-values for the null
hypothesis of normally distributed residuals from both tests are smaller
than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo></mrow><annotation encoding="application/x-tex">1 -</annotation></semantics></math><code>conf.int</code>,
the title of the residual plot will display the message: “Requirement of
normally distributed residuals not met”.</p>
<p>Regardless of the result of the residual analysis,
<code><a href="../reference/visstat.html">visstat()</a></code> proceeds to perform the regression. The title of
the graphical output indicates the chosen confidence level
(<code>conf.level</code>), the estimated regression parameters with
their confidence intervals and p-values, and the adjusted
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>R</mi><mn>2</mn></msup><annotation encoding="application/x-tex">R^2</annotation></semantics></math>.
The plot displays the raw data, the fitted regression line, and both the
confidence and prediction bands corresponding to the specified
<code>conf.level</code>.</p>
<p><code><a href="../reference/visstat.html">visstat()</a></code> returns a list containing the regression test
statistics, the p-values from the normality tests of the standardised
residuals, and the pointwise estimates of the confidence and prediction
bands.</p>
</div>
<div class="section level4">
<h4 id="examples-2">Examples<a class="anchor" aria-label="anchor" href="#examples-2"></a>
</h4>
<div class="section level5">
<h5 id="dataset-cars">dataset: <code class="unnumbered">cars</code><a class="anchor" aria-label="anchor" href="#dataset-cars"></a>
</h5>
<p>The <code>cars</code> dataset reports the speed of cars in miles per
hour (<code>speed</code>) and the stopping distance in feet
(<code>dist</code>).</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">linreg_cars</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">cars</span>, <span class="st">"dist"</span>, <span class="st">"speed"</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-8-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-8-2.png" width="100%"></p>
<p>Increasing the confidence level <code>conf.level</code> from the
default 0.95 to 0.99 results in wider confidence and prediction
bands:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">linreg_cars</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">cars</span>, <span class="st">"dist"</span>, <span class="st">"speed"</span>, conf.level <span class="op">=</span> <span class="fl">0.99</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-9-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-9-2.png" width="100%"></p>
<p>p-values greater than <code>conf.level</code> in both the
Anderson-Darling normality test and the Shapiro–Wilk test of the
standardised residuals indicate that the normality assumption of the
residuals underlying the linear regression is met.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">linreg_trees</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">trees</span>, <span class="st">"Volume"</span>, <span class="st">"Girth"</span>, conf.level <span class="op">=</span> <span class="fl">0.9</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-10-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-10-2.png" width="100%"></p>
</div>
<div class="section level5">
<h5 id="dataset-trees">dataset: <code class="unnumbered">trees</code><a class="anchor" aria-label="anchor" href="#dataset-trees"></a>
</h5>
<p>The <code>trees</code> dataset provides measurements of the diameter
(<code>Girth</code>, in inches), <code>Height</code> (in feet), and
<code>Volume</code> (in cubic feet) of black cherry trees. In this
example, we choose <code>Volume</code> as the response and
<code>Girth</code> as the feature.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">linreg_cars</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">trees</span>, <span class="st">"Volume"</span>, <span class="st">"Girth"</span>, conf.level <span class="op">=</span> <span class="fl">0.9</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-11-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-11-2.png" width="100%"></p>
<p>Both the graphical analysis of the standardised residuals and
p-values greater than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
in the Anderson-Darling and Shapiro–Wilk tests suggest that the
assumption of normally distributed residuals is met. Furthermore, the
linear regression model explains 93% of the total variance in the
response variable <code>Volume</code>.</p>
</div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="categorical-response-and-categorical-feature-1">Categorical response and categorical feature<a class="anchor" aria-label="anchor" href="#categorical-response-and-categorical-feature-1"></a>
</h2>
<!-- When both the feature `varfactor` and the response `varsample` are categorical variables (i.e., of type `factor`), `visstat()` tests the null hypothesis that the two variables are independent. Categorical data are typically represented as contingency tables, which cross-tabulate the observed frequencies for each combination of factor levels. Based on these observed frequencies, `visstat()` computes the expected frequencies under the null hypothesis of independence.  -->
<p>When both <code>varfactor</code> and <code>varsample</code> are
categorical (i.e., of class <code>factor</code>), <code><a href="../reference/visstat.html">visstat()</a></code>
tests the null hypothesis that the two variables are independent.
Observed frequencies are typically arranged in a contingency table,
where rows index the levels
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
of the response variable and columns index the levels
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
of the feature variable.</p>
<div class="section level3">
<h3 id="pearsons-residuals-and-mosaic-plots">Pearson’s residuals and mosaic plots<a class="anchor" aria-label="anchor" href="#pearsons-residuals-and-mosaic-plots"></a>
</h3>
<p>Mosaic plots provide a graphical representation of contingency
tables, where the area of each tile is proportional to the observed cell
frequency. To aid interpretation, tiles are coloured based on Pearson
residuals from a chi-squared test of independence. These residuals
measure the standardised deviation of observed from expected counts
under the null hypothesis of independence.</p>
<p>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>O</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">O_{ij}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">E_{ij}</annotation></semantics></math>
denote the observed and expected frequencies in row
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
and column
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
of an
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">R \times C</annotation></semantics></math>
contingency table. The Pearson residual for each cell is defined as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><msub><mi>O</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><msqrt><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></msqrt></mfrac><mo>,</mo><mspace width="1.0em"></mspace><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>R</mi><mo>,</mo><mspace width="1.0em"></mspace><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>C</mi><mi>.</mi></mrow><annotation encoding="application/x-tex">
r_{ij} = \frac{O_{ij} - E_{ij}}{\sqrt{E_{ij}}}, \quad i = 1, \ldots, R,\quad
j = 1, \ldots, C.
</annotation></semantics></math> Positive residuals (shaded in blue)
indicate observed counts greater than expected, while negative values
suggest under-representation (shaded in red). Colour shading thus
highlights which combinations of categorical levels contribute most to
the overall association.</p>
</div>
<div class="section level3">
<h3 id="pearsons-chi2-test-chisq-test">Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>-test
(<code>chisq.test()</code>)<a class="anchor" aria-label="anchor" href="#pearsons-chi2-test-chisq-test"></a>
</h3>
<p>The test statistic of Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>-test
<span class="citation">(Pearson 1900)</span> is the sum of squared
Pearson residuals:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>χ</mi><mn>2</mn></msup><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>R</mi></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><msubsup><mi>r</mi><mrow><mi>i</mi><mi>j</mi></mrow><mn>2</mn></msubsup><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>R</mi></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><mfrac><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>O</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
\chi^2 = \sum_{i=1}^{R} \sum_{j=1}^{C} r_{ij}^2 =
\sum_{i=1}^{R} \sum_{j=1}^{C} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}.
</annotation></semantics></math></p>
<p>The test statistic is compared to the chi-squared distribution with $
(R - 1)(C - 1)$ degrees of freedom. The resulting p-value corresponds to
the upper tail probability — that is, the probability of observing a
value greater than or equal to the test statistic under the null
hypothesis.</p>
</div>
<div class="section level3">
<h3 id="pearsons-chi2-test-with-yates-continuity-correction">Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>
test with Yates’ continuity correction<a class="anchor" aria-label="anchor" href="#pearsons-chi2-test-with-yates-continuity-correction"></a>
</h3>
<p>Yates’ correction is applied to the Pearson
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>
statistic in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2 \times 2</annotation></semantics></math>
contingency tables (with one degree of freedom). In this case, the
approximation of the discrete sampling distribution by the continuous
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>
distribution tends to overestimate the significance level of the test.
To correct for this, Yates proposed subtracting 0.5 from each absolute
difference between observed and expected counts <span class="citation">(Yates 1934)</span>, resulting in a smaller test
statistic:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>χ</mi><mtext mathvariant="normal">Yates</mtext><mn>2</mn></msubsup><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>2</mn></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mn>2</mn></munderover><mfrac><msup><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mo stretchy="true" form="prefix">|</mo><msub><mi>O</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="true" form="postfix">|</mo></mrow><mo>−</mo><mn>0.5</mn><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex">
\chi^2_{\text{Yates}} = \sum_{i=1}^{2} \sum_{j=1}^{2} 
\frac{(|O_{ij} - E_{ij}| - 0.5)^2}{E_{ij}}.
</annotation></semantics></math></p>
<p>This reduced test statistic yields a larger p-value, thereby lowering
the risk of a Type I error.</p>
<!-- ## Fisher's exact test  -->
<!-- Fisher's exact test [@Fisher:1935] is a non-parametric method that does not   -->
<!-- rely on large-sample approximations. -->
<!-- When any expected frequency $E_{ij}$ is below 5, `visstat()` applies   -->
<!-- Fisher’s exact test using `fisher.test()`. The test calculates an exact   -->
<!-- p-value for testing independence by conditioning on the observed margins:   -->
<!-- the row totals $R_i = \sum_{j=1}^C O_{ij}$ and the column totals   -->
<!-- $C_j = \sum_{i=1}^R O_{ij}$. These margins define the structure of the   -->
<!-- contingency table and remain fixed during the test. -->
<!-- In the $2 \times 2$ case, the p-value is computed from the hypergeometric   -->
<!-- distribution by summing the probabilities of all tables with the same margins   -->
<!-- as the observed one, whose probabilities under the null are less than or equal   -->
<!-- to that of the observed table. -->
<!-- For general $R \times C$ tables, `fisher.test()` generalises this approach   -->
<!-- using the multivariate hypergeometric distribution. -->
</div>
<div class="section level3">
<h3 id="fishers-exact-test-fisher-test">Fisher’s exact test (<code>fisher.test()</code>)<a class="anchor" aria-label="anchor" href="#fishers-exact-test-fisher-test"></a>
</h3>
<p>The
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>
approximation is considered reliable only if no expected cell count is
less than 1 and no more than 20 percent of cells have expected counts
below 5 <span class="citation">(Cochran 1954)</span>). If this condition
is not met, Fisher’s exact test <span class="citation">(Fisher
1971)</span> (<code><a href="https://rdrr.io/r/stats/fisher.test.html" class="external-link">fisher.test()</a></code>) is applied instead, as it is a
non-parametric method that does not rely on large-sample approximations.
The test calculates an exact p-value for testing independence by
conditioning on the observed margins: the row totals
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>i</mi></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></msubsup><msub><mi>O</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">R_i = \sum_{j=1}^C O_{ij}</annotation></semantics></math>
and the column totals
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>j</mi></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>R</mi></msubsup><msub><mi>O</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">C_j = \sum_{i=1}^R O_{ij}</annotation></semantics></math>,
defining the structure of the contingency table.</p>
<p>In the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2 \times 2</annotation></semantics></math>
case, the observed table can be written as:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="center" style="text-align: center"></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>C</mi><mn>1</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><msub><mi>C</mi><mn>2</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><mtext mathvariant="normal">Row sums</mtext></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>R</mi><mn>1</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><mi>a</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>b</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>a</mi><mo>+</mo><mi>b</mi></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><msub><mi>R</mi><mn>2</mn></msub></mtd><mtd columnalign="center" style="text-align: center"><mi>c</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>d</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>c</mi><mo>+</mo><mi>d</mi></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mtext mathvariant="normal">Column sums</mtext></mtd><mtd columnalign="center" style="text-align: center"><mi>a</mi><mo>+</mo><mi>c</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>b</mi><mo>+</mo><mi>d</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>n</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{array}{c|cc|c}
 &amp; C_1 &amp; C_2 &amp; \text{Row sums} \\\\
\hline
R_1 &amp; a &amp; b &amp; a + b \\\\
R_2 &amp; c &amp; d &amp; c + d \\\\
\hline
\text{Column sums} &amp; a + c &amp; b + d &amp; n
\end{array}
</annotation></semantics></math></p>
<p>Let
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mtable><mtr><mtd columnalign="center" style="text-align: center"><mi>a</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>b</mi></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"></mtd></mtr><mtr><mtd columnalign="center" style="text-align: center"><mi>c</mi></mtd><mtd columnalign="center" style="text-align: center"><mi>d</mi></mtd></mtr></mtable><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">
O = \begin{bmatrix} a &amp; b \\\\ c &amp; d \end{bmatrix}
</annotation></semantics></math> denote the above observed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2 \times 2</annotation></semantics></math>
contingency table. The exact probability of observing this table under
the null hypothesis of independence, given the fixed margins, is given
by the hypergeometric probability mass function (PMF)</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ℙ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo>∣</mo><msub><mi>R</mi><mn>1</mn></msub><mo>,</mo><msub><mi>R</mi><mn>2</mn></msub><mo>,</mo><msub><mi>C</mi><mn>1</mn></msub><mo>,</mo><msub><mi>C</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mfrac linethickness="0"><mrow><mi>a</mi><mo>+</mo><mi>b</mi></mrow><mi>a</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mfrac linethickness="0"><mrow><mi>c</mi><mo>+</mo><mi>d</mi></mrow><mi>c</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mfrac linethickness="0"><mi>n</mi><mrow><mi>a</mi><mo>+</mo><mi>c</mi></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex">
\mathbb{P}(O \mid 
R_1, R_2, C_1, C_2) = 
\frac{\binom{a + b}{a} \binom{c + d}{c}}{\binom{n}{a + c}},
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mo>+</mo><mi>c</mi><mo>+</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">n = a + b + c + d</annotation></semantics></math>
is the total sample size.</p>
<!-- Because all other cell values are determined by $a$ and the fixed margins, -->
<!-- this is often written more simply as: -->
<!-- $$ -->
<!-- P(a \mid \text{margins}) = -->
<!-- \frac{\binom{a + b}{a} \binom{c + d}{c}}{\binom{n}{a + c}}. -->
<!-- $$ -->
<p>The p-value is computed by summing the probabilities of all tables
with the same margins whose probabilities under the null are less than
or equal to that of the observed table.</p>
<p>For general
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>×</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">R \times C</annotation></semantics></math>
tables, <code><a href="https://rdrr.io/r/stats/fisher.test.html" class="external-link">fisher.test()</a></code> generalises this approach using the
multivariate hypergeometric distribution.</p>
</div>
<div class="section level3">
<h3 id="test-choice-and-graphical-output">Test choice and graphical output<a class="anchor" aria-label="anchor" href="#test-choice-and-graphical-output"></a>
</h3>
<p>If the expected frequencies are sufficiently large - specifically, if
at least 80% of the cells have expected counts greater than 5 and no
expected count is zero - the function uses Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">{\chi}^2</annotation></semantics></math>-test
(<code><a href="https://rdrr.io/r/stats/chisq.test.html" class="external-link">chisq.test()</a></code>).</p>
<p>Otherwise, it switches to Fisher’s exact test
(<code><a href="https://rdrr.io/r/stats/fisher.test.html" class="external-link">fisher.test()</a></code>) <span class="citation">(Cochran
1954)</span>.</p>
<p>For 2-by-2 contingency tables, Yates’ continuity correction <span class="citation">(Yates 1934)</span> is always applied to Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">{\chi}^2</annotation></semantics></math>-test.</p>
<p>For all tests of independence <code><a href="../reference/visstat.html">visstat()</a></code> displays a
grouped column plot that includes the respective test’s p-value in the
title, as well as a mosaic plot showing colour-coded Pearson residuals
and the p-value of Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>-test.</p>
</div>
<div class="section level3">
<h3 id="transforming-a-contingency-table-to-a-data-frame">Transforming a contingency table to a data frame<a class="anchor" aria-label="anchor" href="#transforming-a-contingency-table-to-a-data-frame"></a>
</h3>
<p>The following examples for tests of categorical feature and response
are all based on the <code>HairEyeColor</code> contingency table.</p>
<p>Contingency tables must be converted to the required column-based
<code>data.frame</code> using the helper function
<code><a href="../reference/counts_to_cases.html">counts_to_cases()</a></code>. The function transforms the contingency
table <code>HairEyeColor</code> into <code>data.frame</code> named
<code>HairEyeColourDataFrame</code>.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">HairEyeColourDataFrame</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/counts_to_cases.html">counts_to_cases</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">HairEyeColor</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="examples-3">Examples<a class="anchor" aria-label="anchor" href="#examples-3"></a>
</h3>
<p>In all examples of this section, we will test the null hypothesis
that hair colour (“Hair”) and eye colour (“Eye”) are independent of each
other.</p>
<div class="section level4">
<h4 id="pearsons-chi2-test">Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">{\chi}^2</annotation></semantics></math>-test
(``)<a class="anchor" aria-label="anchor" href="#pearsons-chi2-test"></a>
</h4>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hair_eye_colour_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/counts_to_cases.html">counts_to_cases</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">HairEyeColor</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">hair_eye_colour_df</span>, <span class="st">"Hair"</span>, <span class="st">"Eye"</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-13-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-13-2.png" width="100%"></p>
<p>The graphical output shows that the null hypothesis of Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>
test – namely, that hair colour and eye colour are independent – must be
rejected at the default significance level
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">\alpha=0.05</annotation></semantics></math>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>2.33</mn><mo>⋅</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>25</mn></mrow></msup><mo>&lt;</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">p = 2.33 \cdot 10^{-25} &lt; \alpha</annotation></semantics></math>).
The mosaic plot indicates that the strongest deviations are due to
over-representation of individuals with black hair and brown eyes, and
of those with blond hair and blue eyes. In contrast, individuals with
blond hair and brown eyes are the most under-represented.</p>
</div>
<div class="section level4">
<h4 id="pearsons-chi2-test-with-yates-continuity-correction-1">Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">{\chi}^2</annotation></semantics></math>-test
with Yate’s continuity correction<a class="anchor" aria-label="anchor" href="#pearsons-chi2-test-with-yates-continuity-correction-1"></a>
</h4>
<p>In the following example, we restrict the data to participants with
either black or brown hair and either brown or blue eyes, resulting in a
2-by-2 contingency table.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hair_black_brown_eyes_brown_blue</span> <span class="op">&lt;-</span> <span class="va">HairEyeColor</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="op">]</span></span>
<span><span class="co"># Transform to data frame</span></span>
<span><span class="va">hair_black_brown_eyes_brown_blue_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/counts_to_cases.html">counts_to_cases</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">hair_black_brown_eyes_brown_blue</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Chi-squared test</span></span>
<span><span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">hair_black_brown_eyes_brown_blue_df</span>, <span class="st">"Hair"</span>, <span class="st">"Eye"</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-14-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-14-2.png" width="100%"></p>
<p>Also in this reduced dataset we reject the null hypothesis of
independence of the hair colors “brown” and “black” from the eye colours
“brown” and ” blue”. The mosaic plot shows that blue eyed persons with
black hair are under-represented. Note the higher p-value of Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">{\chi}^2</annotation></semantics></math>-test
with Yate’s continuity correction (p=0.00354) compared to the p-value of
Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">{\chi}^2</annotation></semantics></math>-test
(p=0.00229) shown in the mosaic plot.</p>
</div>
<div class="section level4">
<h4 id="fishers-exact-test-fisher-test-1">Fisher’s exact test (<code>fisher.test()</code>)<a class="anchor" aria-label="anchor" href="#fishers-exact-test-fisher-test-1"></a>
</h4>
<p>Again, we extract a 2-by-2 contingency table from the full dataset,
this time keeping only male participants with black or brown hair and
hazel or green eyes.</p>
<p>Pearson’s
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">{\chi}^2</annotation></semantics></math>
test applied to this table would yield an expected frequency less than 5
in one of the four cells (25% of all cells), which violates the
requirement that at least 80% of the expected frequencies must be 5 or
greater <span class="citation">(Cochran 1954)</span>.</p>
<p>Therefore, <code><a href="../reference/visstat.html">visstat()</a></code> automatically selects Fisher’s
exact test instead.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hair_eye_colour_male</span> <span class="op">&lt;-</span> <span class="va">HairEyeColor</span><span class="op">[</span>, , <span class="fl">1</span><span class="op">]</span></span>
<span><span class="co"># Slice out a 2 by 2 contingency table</span></span>
<span><span class="va">black_brown_hazel_green_male</span> <span class="op">&lt;-</span> <span class="va">hair_eye_colour_male</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span></span>
<span><span class="co"># Transform to data frame</span></span>
<span><span class="va">black_brown_hazel_green_male</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/counts_to_cases.html">counts_to_cases</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">black_brown_hazel_green_male</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Fisher test</span></span>
<span><span class="va">fisher_stats</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">black_brown_hazel_green_male</span>, <span class="st">"Hair"</span>, <span class="st">"Eye"</span><span class="op">)</span></span></code></pre></div>
<p><img src="visStatistics_files/figure-html/unnamed-chunk-15-1.png" width="100%"><img src="visStatistics_files/figure-html/unnamed-chunk-15-2.png" width="100%"></p>
</div>
</div>
<div class="section level3">
<h3 id="saving-the-graphical-output">Saving the graphical output<a class="anchor" aria-label="anchor" href="#saving-the-graphical-output"></a>
</h3>
<p>All generated graphics can be saved in any file format supported by
<code>Cairo()</code>, including “png”, “jpeg”, “pdf”, “svg”, “ps”, and
“tiff” in the user specified <code>plotDirectory</code>. In the
following example, we store the graphics in <code>png</code> format in
the <code>plotDirectory</code> <code><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempdir()</a></code>. The file names
reflect the statistical test used and the variable names involved.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Graphical output written to plotDirectory: In this example </span></span>
<span><span class="co"># a bar chart to visualise the Chi-squared test and mosaic plot showing</span></span>
<span><span class="co"># Pearson's residuals.</span></span>
<span><span class="co">#chi_squared_or_fisher_Hair_Eye.png and mosaic_complete_Hair_Eye.png</span></span>
<span><span class="fu"><a href="../reference/visstat.html">visstat</a></span><span class="op">(</span><span class="va">black_brown_hazel_green_male</span>, <span class="st">"Hair"</span>, <span class="st">"Eye"</span>,</span>
<span>  graphicsoutput <span class="op">=</span> <span class="st">"png"</span>, plotDirectory <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempdir</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Remove the graphical output from <code>plotDirectory</code>:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/files.html" class="external-link">file.remove</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempdir</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">"chi_squared_or_fisher_Hair_Eye.png"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files.html" class="external-link">file.remove</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempdir</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">"mosaic_complete_Hair_Eye.png"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="implemented-tests">Implemented tests<a class="anchor" aria-label="anchor" href="#implemented-tests"></a>
</h2>
<div class="section level3">
<h3 id="numerical-response-and-categorical-feature-1">Numerical response and categorical feature<a class="anchor" aria-label="anchor" href="#numerical-response-and-categorical-feature-1"></a>
</h3>
<p>When the response is numerical and the feature is categorical, test
of central tendencies are selected:</p>
<p><code><a href="https://rdrr.io/r/stats/t.test.html" class="external-link">t.test()</a></code>, <code><a href="https://rdrr.io/r/stats/wilcox.test.html" class="external-link">wilcox.test()</a></code>,
<code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code>,
<code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code>,<code><a href="https://rdrr.io/r/stats/kruskal.test.html" class="external-link">kruskal.test()</a></code></p>
<div class="section level4">
<h4 id="normality-assumption-check">Normality assumption check<a class="anchor" aria-label="anchor" href="#normality-assumption-check"></a>
</h4>
<p><code><a href="https://rdrr.io/r/stats/shapiro.test.html" class="external-link">shapiro.test()</a></code> and <code>ad.test()</code></p>
</div>
<div class="section level4">
<h4 id="homoscedasticity-assumption-check">Homoscedasticity assumption check<a class="anchor" aria-label="anchor" href="#homoscedasticity-assumption-check"></a>
</h4>
<p><code><a href="https://rdrr.io/r/stats/bartlett.test.html" class="external-link">bartlett.test()</a></code></p>
</div>
<div class="section level4">
<h4 id="post-hoc-tests">Post-hoc tests<a class="anchor" aria-label="anchor" href="#post-hoc-tests"></a>
</h4>
<ul>
<li>
<code><a href="https://rdrr.io/r/stats/TukeyHSD.html" class="external-link">TukeyHSD()</a></code> (for <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code>and
<code><a href="https://rdrr.io/r/stats/oneway.test.html" class="external-link">oneway.test()</a></code>)</li>
<li>
<code><a href="https://rdrr.io/r/stats/pairwise.wilcox.test.html" class="external-link">pairwise.wilcox.test()</a></code> (for
<code><a href="https://rdrr.io/r/stats/kruskal.test.html" class="external-link">kruskal.test()</a></code>)</li>
</ul>
</div>
</div>
<div class="section level3">
<h3 id="numerical-response-and-numerical-feature-2">Numerical response and numerical feature<a class="anchor" aria-label="anchor" href="#numerical-response-and-numerical-feature-2"></a>
</h3>
<p>When both the response and feature are numerical, a simple linear
regression model is fitted:</p>
<p><code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code></p>
</div>
<div class="section level3">
<h3 id="categorical-response-and-categorical-feature-2">Categorical response and categorical feature<a class="anchor" aria-label="anchor" href="#categorical-response-and-categorical-feature-2"></a>
</h3>
<p>When both variables are categorical, <code><a href="../reference/visstat.html">visstat()</a></code> tests the
null hypothesis of independence using one of the following:</p>
<ul>
<li>
<code><a href="https://rdrr.io/r/stats/chisq.test.html" class="external-link">chisq.test()</a></code> (default for larger samples)</li>
<li>
<code><a href="https://rdrr.io/r/stats/fisher.test.html" class="external-link">fisher.test()</a></code> (used for small expected cell counts
based on Cochran’s rule)</li>
</ul>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="bibliography">Bibliography<a class="anchor" aria-label="anchor" href="#bibliography"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Abdi:2007" class="csl-entry">
Abdi, Hervé. 2007. <span>“The Bonferonni and <span>Sidak</span>
Corrections for Multiple Comparisons.”</span> <em>Encyclopedia of
Measurement and Statistics</em>.
</div>
<div id="ref-Cochran:1954" class="csl-entry">
Cochran, William G. 1954. <span>“The <span>Combination</span> of
<span>Estimates</span> from <span>Different Experiments</span>.”</span>
<em>Biometrics</em> 10 (1): 101. <a href="https://doi.org/10.2307/3001666" class="external-link">https://doi.org/10.2307/3001666</a>.
</div>
<div id="ref-Delacre:2017" class="csl-entry">
Delacre, Marie, Daniël Lakens, and Christophe Leys. 2017. <span>“Why
<span>Psychologists Should</span> by <span>Default Use Welch</span>’s
t-Test <span>Instead</span> of <span>Student</span>’s t-Test.”</span>
<em>International Review of Social Psychology</em> 30 (1): 92–101. <a href="https://doi.org/10.5334/irsp.82" class="external-link">https://doi.org/10.5334/irsp.82</a>.
</div>
<div id="ref-Fisher:1935" class="csl-entry">
Fisher, Roland A. 1971. <em>The Design of Experiments</em>. 9th ed.
Macmillan.
</div>
<div id="ref-Hollander:2014" class="csl-entry">
Hollander, Myles, Eric Chicken, and Douglas A. Wolfe. 2014.
<em>Nonparametric Statistical Methods</em>. Third edition. Wiley Series
in Probability and Statistics. Hoboken, New Jersey: John Wiley &amp;
Sons, Inc.
</div>
<div id="ref-Holm:1979" class="csl-entry">
Holm, Sture. 1979. <span>“A <span>Simple Sequentially Rejective Multiple
Test Procedure</span>.”</span> <em>Scandinavian Journal of
Statistics</em> 6 (2): 65–70. <a href="https://www.jstor.org/stable/4615733" class="external-link">https://www.jstor.org/stable/4615733</a>.
</div>
<div id="ref-Kruskal:1952" class="csl-entry">
Kruskal, William H., and W. Allen Wallis. 1952. <span>“Use of
<span>Ranks</span> in <span>One-Criterion Variance
Analysis</span>.”</span> <em>Journal of the American Statistical
Association</em> 47 (260): 583–621. <a href="https://doi.org/10.2307/2280779" class="external-link">https://doi.org/10.2307/2280779</a>.
</div>
<div id="ref-Lumley:2002" class="csl-entry">
Lumley, Thomas, Paula Diehr, Scott Emerson, and Lu Chen. 2002.
<span>“The Importance of the Normality Assumption in Large Public Health
Data Sets.”</span> <em>Annual Review of Public Health</em> 23: 151–69.
<a href="https://doi.org/10.1146/annurev.publhealth.23.100901.140546" class="external-link">https://doi.org/10.1146/annurev.publhealth.23.100901.140546</a>.
</div>
<div id="ref-Mann:1947" class="csl-entry">
Mann, Henry B., and Donald R. Whitney. 1947. <span>“On a Test of Whether
One of Two Random Variables Is Stochastically Larger Than the
Other.”</span> <em>The Annals of Mathematical Statistics</em> 18 (1):
50–60. <a href="https://doi.org/10.1214/aoms/1177730491" class="external-link">https://doi.org/10.1214/aoms/1177730491</a>.
</div>
<div id="ref-Moser:1992" class="csl-entry">
Moser, B K, and G. R. Stevens. 1992. <span>“Homogeneity of Variance in
the Two-Sample Means Test.”</span> <em>The American Statistician</em>,
February, 19–21. <a href="https://doi.org/10.1080/00031305.1992.10475839" class="external-link">https://doi.org/10.1080/00031305.1992.10475839</a>.
</div>
<div id="ref-Pearson:1900" class="csl-entry">
Pearson, Karl. 1900. <span>“On the Criterion That a Given System of
Deviations from the Probable in the Case of a Correlated System of
Variables Is Such That It Can Be Reasonably Supposed to Have Arisen from
Random Sampling.”</span> <em>The London, Edinburgh, and Dublin
Philosophical Magazine and Journal of Science</em> 50 (302): 157–75. <a href="https://doi.org/10.1080/14786440009463897" class="external-link">https://doi.org/10.1080/14786440009463897</a>.
</div>
<div id="ref-Rasch:2011" class="csl-entry">
Rasch, Dieter, Klaus D. Kubinger, and Karl Moder. 2011. <span>“The
Two-Sample t Test: Pre-Testing Its Assumptions Does Not Pay Off.”</span>
<em>Statistical Papers</em> 52 (1): 219–31. <a href="https://doi.org/10.1007/s00362-009-0224-x" class="external-link">https://doi.org/10.1007/s00362-009-0224-x</a>.
</div>
<div id="ref-Satterthwaite:1946" class="csl-entry">
Satterthwaite, F. E. 1946. <span>“An <span>Approximate
Distribution</span> of <span>Estimates</span> of <span>Variance
Components</span>.”</span> <em>Biometrics Bulletin</em> 2 (6): 110–14.
<a href="https://doi.org/10.2307/3002019" class="external-link">https://doi.org/10.2307/3002019</a>.
</div>
<div id="ref-Sidak:1967" class="csl-entry">
Šidák, Zbyněk. 1967. <span>“Rectangular Confidence Regions for the Means
of Multivariate Normal Distributions.”</span> <em>Journal of the
American Statistical Association</em> 62 (318): 626–33. <a href="https://doi.org/10.1080/01621459.1967.10482935" class="external-link">https://doi.org/10.1080/01621459.1967.10482935</a>.
</div>
<div id="ref-Welch:1947" class="csl-entry">
Welch, B. L. 1947. <span>“The Generalization of <span>‘Student’s’</span>
Problem When Several Different Population Variances Are
Involved.”</span> <em>Biometrika</em> 34 (1–2): 28–35. <a href="https://doi.org/10.1093/biomet/34.1-2.28" class="external-link">https://doi.org/10.1093/biomet/34.1-2.28</a>.
</div>
<div id="ref-Welch:1951" class="csl-entry">
———. 1951. <span>“On the <span>Comparison</span> of <span>Several Mean
Values</span>: <span>An Alternative Approach</span>.”</span>
<em>Biometrika</em> 38 (3/4): 330–36. <a href="https://doi.org/10.2307/2332579" class="external-link">https://doi.org/10.2307/2332579</a>.
</div>
<div id="ref-Wilcoxon:1945" class="csl-entry">
Wilcoxon, Frank. 1945. <span>“Individual Comparisons by Ranking
Methods.”</span> <em>Biometrics Bulletin</em> 1 (6): 80–83. <a href="https://doi.org/10.2307/3001968" class="external-link">https://doi.org/10.2307/3001968</a>.
</div>
<div id="ref-Yates:1934" class="csl-entry">
Yates, F. 1934. <span>“Contingency <span>Tables Involving Small
Numbers</span> and the
<span><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math></span>2
<span>Test</span>.”</span> <em>Journal of the Royal Statistical Society
Series B: Statistical Methodology</em> 1 (2): 217–35. <a href="https://doi.org/10.2307/2983604" class="external-link">https://doi.org/10.2307/2983604</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Sabine Schilling.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer>
</div>





  </body>
</html>
